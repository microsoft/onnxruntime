<p align="center">
  <a href="README.md">Fran√ßais</a> | <b>English</b> | <a href="README.es.md">Espa√±ol</a> | <a href="README.de.md">Deutsch</a>
</p>

<p align="center">
  <img width="50%" src="docs/images/ONNX_Runtime_logo_dark.png" alt="ONNX Runtime Logo" />
</p>

<h1 align="center">ONNX Runtime</h1>

<p align="center">
  <strong>A cross-platform inference and training machine-learning accelerator.</strong>
</p>

<p align="center">
  <a href="https://github.com/microsoft/onnxruntime/releases"><img src="https://img.shields.io/github/v/release/microsoft/onnxruntime?style=for-the-badge" alt="Release"></a>
  <a href="LICENSE"><img src="https://img.shields.io/github/license/microsoft/onnxruntime?style=for-the-badge" alt="License"></a>
  <a href="https://github.com/Microsoft/onnxruntime/issues"><img src="https://img.shields.io/github/issues/microsoft/onnxruntime?style=for-the-badge" alt="Open Issues"></a>
</p>

---

## üöÄ What is ONNX Runtime?

**ONNX Runtime** is a high-performance accelerator for machine learning models, handling both inference and training.

* **‚ö° For Inference:** Enable faster customer experiences and lower costs. ONNX Runtime supports models from popular frameworks like **PyTorch** and **TensorFlow/Keras**, as well as classical libraries such as **scikit-learn**, **LightGBM**, and **XGBoost**. It's compatible with different hardware, drivers, and operating systems, providing optimal performance by leveraging hardware accelerators and graph optimizations. [Learn more &rarr;](https://www.onnxruntime.ai/docs/#onnx-runtime-for-inferencing)

* **üß† For Training:** Accelerate model training time on multi-node NVIDIA GPUs for transformer models. It requires just a one-line addition to your existing PyTorch training scripts. [Learn more &rarr;](https://www.onnxruntime.ai/docs/#onnx-runtime-for-training)

## üìö Get Started & Resources

All the information you need to get started or dive deeper.

| Resource | Description |
| :--- | :--- |
| üåê **Website** | [onnxruntime.ai](https://onnxruntime.ai) - General information. |
| üìñ **Documentation** | [onnxruntime.ai/docs](https://onnxruntime.ai/docs) - Usage guides and tutorials. |
| üì∫ **Video Tutorials** | [youtube.com/@ONNXRuntime](https://www.youtube.com/@ONNXRuntime) - Visual learning. |
| üõ£Ô∏è **Roadmap** | [onnxruntime.ai/roadmap](https://onnxruntime.ai/roadmap) - See upcoming features. |
| üí° **Examples (Inference)** | [microsoft/onnxruntime-inference-examples](https://github.com/microsoft/onnxruntime-inference-examples) - Companion code repository. |
| üèãÔ∏è **Examples (Training)** | [microsoft/onnxruntime-training-examples](https://github.com/microsoft/onnxruntime-training-examples) - Companion code repository. |

## üì¶ Releases

Find the current release and past releases here:
[**github.com/microsoft/onnxruntime/releases**](https://github.com/microsoft/onnxruntime/releases)

For details on the upcoming release (dates, announcements, new features), please visit our [public roadmap](https://onnxruntime.ai/roadmap).

## ü§ù Contributions and Feedback

We welcome your help!

* **Want to contribute?** Please see the [**contribution guidelines**](CONTRIBUTING.md).
* **Report a bug or request a feature?** File a [**GitHub Issue**](https://github.com/Microsoft/onnxruntime/issues).
* **Have a question or want to discuss?** Use [**GitHub Discussions**](https://github.com/microsoft/onnxruntime/discussions).

---

## üìä Data/Telemetry

> Windows distributions of this project may collect usage data and send it to Microsoft to help improve our products and services.
> See the [**privacy statement**](docs/Privacy.md) for more details.

## ‚öñÔ∏è Code of Conduct & License

* This project has adopted the [**Microsoft Open Source Code of Conduct**](https://opensource.microsoft.com/codeofconduct/). For more information, see the [Code of Conduct FAQ](https://opensource.microsoft.com/codeofconduct/faq/) or contact [opencode@microsoft.com](mailto:opencode@microsoft.com).
* This project is licensed under the [**MIT License**](LICENSE).
