<p align="center">
  <a href="README.md">English</a> | <a href="README.fr.md">French</a> | <a href="README.es.md">Espa√±ol</a> | <b>Deutsch</b>
</p>

<p align="center">
  <img width="50%" src="docs/images/ONNX_Runtime_logo_dark.png" alt="ONNX Runtime Logo" />
</p>

<h1 align="center">ONNX Runtime</h1>

<p align="center">
  <strong>Ein plattform√ºbergreifender Beschleuniger f√ºr Inferenz und Training von Machine-Learning-Modellen.</strong>
</p>

<p align="center">
  <a href="https://github.com/microsoft/onnxruntime/releases"><img src="https://img.shields.io/github/v/release/microsoft/onnxruntime?style=for-the-badge" alt="Version"></a>
  <a href="LICENSE"><img src="https://img.shields.io/github/license/microsoft/onnxruntime?style=for-the-badge" alt="Lizenz"></a>
  <a href="https://github.com/Microsoft/onnxruntime/issues"><img src="https://img.shields.io/github/issues/microsoft/onnxruntime?style=for-the-badge" alt="Offene Issues"></a>
</p>

---

## üöÄ Was ist ONNX Runtime?

**ONNX Runtime** ist ein Hochleistungsbeschleuniger f√ºr Machine-Learning-Modelle, der sowohl Inferenz als auch Training handhabt.

* **‚ö° F√ºr Inferenz:** Erm√∂glichen Sie schnellere Kundenerlebnisse und senken Sie Kosten. ONNX Runtime unterst√ºtzt Modelle aus g√§ngigen Frameworks wie **PyTorch** und **TensorFlow/Keras** sowie aus klassischen Bibliotheken wie **scikit-learn**, **LightGBM** und **XGBoost**. Es ist kompatibel mit verschiedener Hardware, Treibern und Betriebssystemen und bietet optimale Leistung durch die Nutzung von Hardware-Beschleunigern und Graph-Optimierungen. [Mehr erfahren &rarr;](https://www.onnxruntime.ai/docs/#onnx-runtime-for-inferencing)

* **üß† F√ºr Training:** Beschleunigen Sie die Trainingszeit von Transformer-Modellen auf Multi-Node-NVIDIA-GPUs. Es erfordert nur das Hinzuf√ºgen einer einzigen Zeile zu Ihren bestehenden PyTorch-Trainingsskripten. [Mehr erfahren &rarr;](https://www.onnxruntime.ai/docs/#onnx-runtime-for-training)

## üìö Erste Schritte & Ressourcen

Alle Informationen, die Sie f√ºr den Einstieg oder zur Vertiefung ben√∂tigen.

| Ressource | Beschreibung |
| :--- | :--- |
| üåê **Website** | [onnxruntime.ai](https://onnxruntime.ai) - Allgemeine Informationen. |
| üìñ **Dokumentation** | [onnxruntime.ai/docs](https://onnxruntime.ai/docs) - Nutzungsanleitungen und Tutorials. |
| üì∫ **Video-Tutorials** | [youtube.com/@ONNXRuntime](https://www.youtube.com/@ONNXRuntime) - Visuelles Lernen. |
| üõ£Ô∏è **Roadmap** | [onnxruntime.ai/roadmap](https://onnxruntime.ai/roadmap) - Sehen Sie kommende Funktionen. |
| üí° **Beispiele (Inferenz)** | [microsoft/onnxruntime-inference-examples](https://github.com/microsoft/onnxruntime-inference-examples) - Begleitendes Code-Repository. |
| üèãÔ∏è **Beispiele (Training)** | [microsoft/onnxruntime-training-examples](https://github.com/microsoft/onnxruntime-training-examples) - Begleitendes Code-Repository. |

## üì¶ Versionen (Releases)

Finden Sie die aktuelle Version und vergangene Versionen hier:
[**github.com/microsoft/onnxruntime/releases**](https://github.com/microsoft/onnxruntime/releases)

Details zur kommenden Version (Termine, Ank√ºndigungen, neue Funktionen) finden Sie in unserer [√∂ffentlichen Roadmap](https://onnxruntime.ai/roadmap).

## ü§ù Beitr√§ge und Feedback

Wir freuen uns √ºber Ihre Hilfe!

* **M√∂chten Sie beitragen?** Bitte beachten Sie die [**Beitragsvorgaben**](CONTRIBUTING.md).
* **Einen Fehler melden oder eine Funktion anfragen?** Erstellen Sie ein [**GitHub Issue**](https://github.com/Microsoft/onnxruntime/issues).
* **Haben Sie eine Frage oder m√∂chten Sie diskutieren?** Nutzen Sie [**GitHub Discussions**](https://github.com/microsoft/onnxruntime/discussions).

---

## üìä Daten/Telemetrie

> Windows-Distributionen dieses Projekts k√∂nnen Nutzungsdaten sammeln und an Microsoft senden, um uns bei der Verbesserung unserer Produkte und Dienstleistungen zu helfen.
> Weitere Details finden Sie in der [**Datenschutzerkl√§rung**](docs/Privacy.md).

## ‚öñÔ∏è Verhaltenskodex & Lizenz

* Dieses Projekt hat den [**Microsoft Open Source-Verhaltenskodex**](https://opensource.microsoft.com/codeofconduct/) √ºbernommen. Weitere Informationen finden Sie in den [FAQ zum Verhaltenskodex](https://opensource.microsoft.com/codeofconduct/faq/) oder kontaktieren Sie [opencode@microsoft.com](mailto:opencode@microsoft.com).
* Dieses Projekt ist unter der [**MIT-Lizenz**](LICENSE) lizenziert.
