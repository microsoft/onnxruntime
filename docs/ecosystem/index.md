---
title: Ecosystem
description: See examples of how ONNX Runtime working end to end within the Azure AI and ML landscape and ecosystem
nav_order: 9
redirect_from: /docs/tutorials/ecosystem
---
# ORT Ecosystem
{: .no_toc }

ONNX Runtime functions as part of an ecosystem of tools and platforms to deliver an end-to-end machine learning experience. Below are tutorials for some products that work with or integrate ONNX Runtime.

## Contents
{: .no_toc }

* TOC placeholder
{:toc}


## Azure Machine Learning Services
* [Azure Container Instance: BERT](https://github.com/microsoft/onnxruntime/tree/main/onnxruntime/python/tools/transformers/notebooks/Inference_Bert_with_OnnxRuntime_on_AzureML.ipynb){:target="_blank"}
* [Azure Container Instance: Facial Expression Recognition](https://github.com/Azure/MachineLearningNotebooks/blob/master/how-to-use-azureml/deployment/onnx/onnx-inference-facial-expression-recognition-deploy.ipynb){:target="_blank"}
* [Azure Container Instance: MNIST](https://github.com/Azure/MachineLearningNotebooks/blob/master/how-to-use-azureml/deployment/onnx/onnx-inference-mnist-deploy.ipynb){:target="_blank"}
* [Azure Container Instance: Image classification (Resnet)](https://github.com/Azure/MachineLearningNotebooks/blob/master/how-to-use-azureml/deployment/onnx/onnx-modelzoo-aml-deploy-resnet50.ipynb){:target="_blank"}
* [Azure Kubernetes Services: FER+](https://github.com/microsoft/onnxruntime/blob/main/docs/python/notebooks/onnx-inference-byoc-gpu-cpu-aks.ipynb){:target="_blank"}
* [Azure IoT Sedge (Intel UP2 device with OpenVINO)](https://github.com/Azure-Samples/onnxruntime-iot-edge/blob/master/AzureML-OpenVINO/README.md){:target="_blank"}
* [Automated Machine Learning](https://github.com/Azure/MachineLearningNotebooks/blob/master/how-to-use-azureml/automated-machine-learning/classification-bank-marketing-all-features/auto-ml-classification-bank-marketing-all-features.ipynb){:target="_blank"}

## Azure Custom Vision
* [Export a Custom Vision model to ONNX format](https://learn.microsoft.com/en-us/azure/cognitive-services/custom-vision-service/export-programmatically){:target="_blank"}
* [Use a Custom Vision model with Windows Machine Learning](https://docs.microsoft.com/en-us/azure/cognitive-services/custom-vision-service/custom-vision-onnx-windows-ml){:target="_blank"}

## Azure SQL Edge
* [ML predictions in Azure SQL Edge and Azure SQL Managed Instance](https://docs.microsoft.com/en-us/azure/azure-sql-edge/deploy-onnx){:target="_blank"}

## Azure Synapse Analytics
* [ML predictions in Synapse SQL](https://docs.microsoft.com/en-us/azure/synapse-analytics/sql-data-warehouse/sql-data-warehouse-predict){:target="_blank"}


## ML.NET
* [Automated Machine Learning](https://docs.microsoft.com/en-us/azure/machine-learning/how-to-use-automl-onnx-model-dotnet?toc=/dotnet/machine-learning/how-to-guides/toc.json&bc=/dotnet/machine-learning/how-to-guides/toc.json){:target="_blank"}
* [Inference: Object detection](https://docs.microsoft.com/en-us/dotnet/machine-learning/tutorials/object-detection-onnx){:target="_blank"}

## NVIDIA Triton Inference Server
* [ONNX Runtime backend for Triton](https://github.com/triton-inference-server/onnxruntime_backend){:target="_blank"}
