trigger: none

pr:
  branches:
    include:
    - main
    - rel-*
  paths:
    exclude:
    - 'js/web'
    - 'onnxruntime/core/providers/js'
name: 'orttraining_ci_$(Date:yyyyMMdd)_$(Rev:r)'

variables:
  - name: video
    value: 44
  - name: render
    value: 109
  - name: RocmVersion
    value: 5.6
  - name: BuildConfig
    value: Release

jobs:
- job: Linux_Build
  variables:
    skipComponentGovernanceDetection: true
    CCACHE_DIR: $(Pipeline.Workspace)/ccache
    TODAY: $[format('{0:dd}{0:MM}{0:yyyy}', pipeline.startTime)]
  workspace:
    clean: all
  pool: onnxruntime-Ubuntu2004-AMD-CPU
  timeoutInMinutes: 120

  steps:
  - task: mspremier.PostBuildCleanup.PostBuildCleanup-task.PostBuildCleanup@3
    displayName: 'Clean Agent Directories'
    condition: always()

  - checkout: self
    clean: true
    submodules: recursive

  - template: templates/get-docker-image-steps.yml
    parameters:
      Dockerfile: tools/ci_build/github/pai/rocm-ci-pipeline-env.Dockerfile
      Context: tools/ci_build/github/linux/docker
      DockerBuildArgs: "--build-arg ROCM_VERSION=$(RocmVersion)"
      Repository: onnxruntimetrainingrocm-cibuild-rocm$(RocmVersion)-build

  #- script: |-
  #    sed -i 's|session_options.use_deterministic_compute = False|session_options.use_deterministic_compute = True|g' \
  #       orttraining/orttraining/python/training/ortmodule/_graph_execution_manager.py
  #  displayName: 'Toggle ON deterministic compute mode for ORTModule'

  - task: Cache@2
    inputs:
      key: '"$(TODAY)" | "$(Build.SourceBranch)" | "$(Build.SourceVersion)"'
      path: $(CCACHE_DIR)
      cacheHitVar: CACHE_RESTORED
      restoreKeys: |
        "$(TODAY)" | "$(Build.SourceBranch)"
        "$(TODAY)" |
    displayName: Cache Task

  - script: mkdir -p $(CCACHE_DIR)
    condition: ne(variables.CACHE_RESTORED, 'true')
    displayName: Create Cache Dir

  - task: CmdLine@2
    inputs:
      script: |-
        export ROCM_HOME=/opt/rocm
        docker run --rm \
          --security-opt seccomp=unconfined \
          --shm-size=1024m \
          --user $UID:$(id -g $USER) \
          --volume $(Build.SourcesDirectory):/onnxruntime_src \
          --volume $(Build.BinariesDirectory):/build \
          --volume $(CCACHE_DIR):/cache \
          -e CCACHE_DIR=/cache \
          --workdir /onnxruntime_src \
          onnxruntimetrainingrocm-cibuild-rocm$(RocmVersion)-build \
          /bin/bash -c "
            set -ex; \
            ccache -s; \
            python tools/ci_build/build.py \
              --config $(BuildConfig) \
              --enable_training \
              --mpi_home /opt/ompi \
              --cmake_extra_defines \
                CMAKE_HIP_COMPILER=${ROCM_HOME}/llvm/bin/clang++ \
                onnxruntime_BUILD_KERNEL_EXPLORER=ON \
              --use_cache \
              --use_rocm \
              --rocm_version=$(RocmVersion) \
              --rocm_home ${ROCM_HOME} \
              --nccl_home ${ROCM_HOME}\
              --update \
              --build_dir /build \
              --build \
              --parallel \
              --build_wheel \
              --skip_submodule_sync \
              --skip_tests; \
            ccache -sv; \
            ccache -z"
    displayName: 'Build onnxruntime'

  - task: PublishPipelineArtifact@0
    displayName: 'Publish Pipeline Artifact'
    inputs:
      artifactName: 'drop-linux'
      targetPath: '$(Build.BinariesDirectory)/Release'

  - template: templates/explicitly-defined-final-tasks.yml


- job: Linux_Test
  workspace:
    clean: all
  pool: AMD-GPU
  dependsOn:
  - Linux_Build
  timeoutInMinutes: 120

  steps:
  - task: DownloadPipelineArtifact@2
    displayName: 'Download Pipeline Artifact'
    inputs:
      buildType: 'current'
      artifactName: 'drop-linux'
      targetPath: '$(Build.BinariesDirectory)/Release'

  - checkout: self
    clean: true
    submodules: recursive

  - template: templates/get-docker-image-steps.yml
    parameters:
      Dockerfile: tools/ci_build/github/pai/rocm-ci-pipeline-env.Dockerfile
      Context: tools/ci_build/github/linux/docker
      DockerBuildArgs: "--build-arg BUILD_UID=$( id -u ) --build-arg ROCM_VERSION=$(RocmVersion)"
      Repository: onnxruntimetrainingrocm-cibuild-rocm$(RocmVersion)-test

  - task: Bash@3
    inputs:
      targetType: filePath
      filePath: $(Build.SourcesDirectory)/tools/ci_build/github/pai/pai_clean_device.sh
      arguments: -n $(Agent.Name) -d $HIP_VISIBLE_DEVICES -r $DRIVER_RENDER
    displayName: 'Check ROCm Environment'

  - task: CmdLine@2
    inputs:
      script: |-
        docker run --rm \
          --security-opt seccomp=unconfined \
          --shm-size=1024m \
          --device=/dev/kfd \
          --device=/dev/dri/renderD$DRIVER_RENDER \
          --group-add $(video) \
          --group-add $(render) \
          --user onnxruntimedev \
          --volume $(Build.SourcesDirectory):/onnxruntime_src \
          --volume $(Build.BinariesDirectory):/build \
          --workdir /build/$(BuildConfig) \
          onnxruntimetrainingrocm-cibuild-rocm$(RocmVersion)-test \
          /bin/bash -c "
            set -ex; \
            chmod a+x /build/Release/onnxruntime_test_all; \
            /onnxruntime_src/tools/ci_build/github/pai/pai_test_launcher.sh"
      workingDirectory: $(Build.SourcesDirectory)
    displayName: 'Run onnxruntime unit tests'
    condition: succeeded()

  - task: CmdLine@2
    inputs:
      script: |-
        docker run --rm \
          --security-opt seccomp=unconfined \
          --shm-size=1024m \
          --device=/dev/kfd \
          --device=/dev/dri/renderD$DRIVER_RENDER \
          --group-add $(video) \
          --group-add $(render) \
          --user onnxruntimedev \
          --volume $(Build.SourcesDirectory):/onnxruntime_src \
          --volume $(Build.BinariesDirectory):/build \
          -e OPENBLAS_NUM_THREADS=1 \
          -e OPENMP_NUM_THREADS=1 \
          -e MKL_NUM_THREADS=1 \
          -e KERNEL_EXPLORER_BUILD_DIR=/build/$(BuildConfig) \
          -e KERNEL_EXPLORER_BATCHED_GEMM_MAX_BATCH_SIZE=8 \
          -e KERNEL_EXPLORER_TEST_USE_CUPY=1 \
          onnxruntimetrainingrocm-cibuild-rocm$(RocmVersion)-test \
            pytest /onnxruntime_src/onnxruntime/python/tools/kernel_explorer/ -n 4 --reruns 1 --durations=100
      workingDirectory: $(Build.SourcesDirectory)
    displayName: 'Run kernel explorer tests'
    condition: succeededOrFailed()

  - task: CmdLine@2
    inputs:
      script: |-
        docker run --rm \
          --security-opt seccomp=unconfined \
          --shm-size=1024m \
          --device=/dev/kfd \
          --device=/dev/dri/renderD$DRIVER_RENDER \
          --group-add $(video) \
          --group-add $(render) \
          --user onnxruntimedev \
          --volume $(Build.SourcesDirectory):/onnxruntime_src \
          --volume $(Build.BinariesDirectory):/build \
          --workdir /build/$(BuildConfig) \
          onnxruntimetrainingrocm-cibuild-rocm$(RocmVersion)-test \
            /bin/bash -c "
              set -ex; \
              export PYTHONPATH=/build/$(BuildConfig); \
              python -m onnxruntime.training.ortmodule.torch_cpp_extensions.install; \
              bash /onnxruntime_src/tools/ci_build/github/pai/pai_huggingface_bert_large_test.sh -v $(RocmVersion)"
      workingDirectory: $(Build.SourcesDirectory)
    displayName: 'Run Python Hugging-Face BERT-L test'
    condition: succeededOrFailed()


  # Entry point for all ORTModule tests
  # The onnxruntime folder is deleted in the build directory
  # to enforce use of the onnxruntime wheel
  - task: CmdLine@2
    inputs:
      script: |-
        rm -rf $(Build.BinariesDirectory)/$(BuildConfig)/onnxruntime/
        files=($(Build.BinariesDirectory)/$(BuildConfig)/dist/*.whl)
        echo ${files[0]}
        whlfilename=$(basename ${files[0]})
        echo $whlfilename
        docker run --rm \
          --security-opt seccomp=unconfined \
          --shm-size=1024m \
          --device=/dev/kfd \
          --device=/dev/dri/renderD$DRIVER_RENDER \
          --group-add $(video) \
          --group-add $(render) \
          --user onnxruntimedev \
          --volume $(Build.BinariesDirectory):/build \
          --volume $(Build.SourcesDirectory):/onnxruntime_src \
          --workdir /build/$(BuildConfig) \
          onnxruntimetrainingrocm-cibuild-rocm$(RocmVersion)-test \
            /bin/bash -c "
              set -ex; \
              unset PYTHONPATH; \
              pip install /build/$(BuildConfig)/dist/$whlfilename; \
              python -m onnxruntime.training.ortmodule.torch_cpp_extensions.install; \
              mkdir /home/onnxruntimedev/mnist /home/onnxruntimedev/bert_data; \
              export ORTMODULE_DISABLE_CPU_TRAINING_TEST=1; \
              export ORTMODULE_ROCM_TEST=1; \
              python orttraining_ortmodule_tests.py \
                --mnist /home/onnxruntimedev/mnist \
                --bert_data /home/onnxruntimedev/bert_data/hf_data/glue_data/CoLA/original/raw"
      workingDirectory: $(Build.SourcesDirectory)
    displayName: 'Run orttraining_ortmodule_tests.py'
    condition: succeededOrFailed()


  - task: Bash@3
    inputs:
      targetType: filePath
      filePath: $(Build.SourcesDirectory)/tools/ci_build/github/pai/pai_clean_device.sh
      arguments: -n $(Agent.Name) -d $HIP_VISIBLE_DEVICES -r $DRIVER_RENDER
    displayName: 'Clean ROCm Environment'
    condition: always()

  - template: templates/clean-agent-build-directory-step.yml
