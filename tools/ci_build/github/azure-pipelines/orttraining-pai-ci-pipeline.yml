trigger: none

name: 'orttraining_ci_$(Date:yyyyMMdd)_$(Rev:r)'
jobs:
- job: AMD_CI
  pool: 'AMD-GPU'
  timeoutInMinutes: 120
  
  # gid of video and render group on gcr-openpai-35 and -36
  variables:
    - name: video
      value: 44
    - name: render
      value: 109
    - name: onnxruntimeBuildSucceeded
      value: false
  
  # generated from tools/ci_build/github/pai/rocm-ci-pipeline-env.Dockerfile 
  container: 
    image: onnxruntimecibuildenvironment.azurecr.io/rocm-ci-pipeline-env
    endpoint: onnxruntimecibuildenvironmentforamd
    options: --privileged -e HIP_VISIBLE_DEVICES --security-opt seccomp=unconfined --device=/dev/kfd --device=/dev/dri  --group-add $(video) --group-add $(render)
  
  steps:
  - checkout: self
    clean: true
  
  - script: |-
      echo "Selecting GPU based on HIP_VISIBLE_DEVICES=$HIP_VISIBLE_DEVICES"
    displayName: 'Initialize environment'
  
  #- script: |-
  #    sed -i 's|session_options.use_deterministic_compute = False|session_options.use_deterministic_compute = True|g' \
  #       orttraining/orttraining/python/training/ortmodule/_graph_execution_manager.py
  #  displayName: 'Toggle ON deterministic compute mode for ORTModule'

  - task: CmdLine@2
    displayName: 'Check ROCm Environment'
    inputs:
      script: |-
        echo $(Agent.Name)
        bash ./tools/ci_build/github/pai/pai_get_thread.sh $(Agent.Name)
    target: host

  - task: CmdLine@2
    inputs:
      script: |-
        export ROCM_HOME=/opt/rocm
        python tools/ci_build/build.py \
        --config RelWithDebInfo \
        --enable_training \
        --mpi_home /opt/ompi \
        --use_rocm \
        --rocm_version=4.3.1 \
        --rocm_home /opt/rocm \
        --nccl_home /opt/rocm \
        --update \
        --build_dir ./build \
        --build \
        --parallel 8 \
        --build_wheel \
        --skip_tests
    displayName: 'Build onnxruntime'
    
  - bash: |-
      echo "##vso[task.setvariable variable=onnxruntimeBuildSucceeded]true"
    displayName: 'Set Onnxruntime Build Succeeded'
  
  - task: CmdLine@2
    inputs:
      script: |-
        cd ./build/RelWithDebInfo &&\
        ../../tools/ci_build/github/pai/pai_test_launcher.sh
    displayName: 'Run onnxruntime unit tests'
    
  - task: CmdLine@2
    inputs:
      script: |-
        cd ./build/RelWithDebInfo
        export PYTHONPATH=$PWD
        python -m onnxruntime.training.ortmodule.torch_cpp_extensions.install
    displayName: 'Compile torch extensions into build directory'
    condition: and(succeededOrFailed(), eq(variables.onnxruntimeBuildSucceeded, 'true')) # ensure all tests are run when the build successed
  
  - task: CmdLine@2
    inputs:
      script: |-
        cd ./build/RelWithDebInfo
        export PYTHONPATH=$PWD
        export ORTMODULE_ONNX_OPSET_VERSION=12
        python \
          /stage/huggingface-transformers/examples/pytorch/language-modeling/run_mlm.py \
          --model_name_or_path bert-large-uncased \
          --dataset_name wikitext \
          --dataset_config_name wikitext-2-raw-v1 \
          --do_train \
          --max_steps 260 \
          --logging_steps 20 \
          --output_dir ./test-mlm-bbu \
          --overwrite_output_dir \
          --per_device_train_batch_size 8 \
          --fp16 \
          --dataloader_num_workers 1 \
          --ort \
          --skip_memory_metrics
        python ../../orttraining/tools/ci_test/compare_huggingface.py \
          ci-pipeline-actual.json \
          ../../orttraining/tools/ci_test/results/ci-mi100.huggingface.bert-large-rocm4.3.1.json
    displayName: 'Run Python Hugging-Face BERT-L test'
    retryCountOnTaskFailure: 1
    condition: and(succeededOrFailed(), eq(variables.onnxruntimeBuildSucceeded, 'true')) # ensure all tests are run when the build successed
  
  - task: CmdLine@2
    inputs:
      script: |-
        cd ./build/RelWithDebInfo
        export PYTHONPATH=$PWD
        export ORTMODULE_ONNX_OPSET_VERSION=12
        python \
          /stage/huggingface-transformers/examples/pytorch/language-modeling/run_clm.py \
          --model_name_or_path gpt2 \
          --dataset_name wikitext \
          --dataset_config_name wikitext-2-raw-v1 \
          --do_train \
          --label_smoothing 0.1 \
          --max_steps 260 \
          --logging_steps 20 \
          --overwrite_output_dir \
          --output_dir ./test-clm \
          --per_device_train_batch_size 8 \
          --fp16 \
          --dataloader_num_workers 1 \
          --ort \
          --skip_memory_metrics
        python ../../orttraining/tools/ci_test/compare_huggingface.py \
          ci-pipeline-actual.json \
          ../../orttraining/tools/ci_test/results/ci-mi100.huggingface.gpt2-rocm4.3.1.json
    displayName: 'Run Python Hugging-Face GPT2 test'
    retryCountOnTaskFailure: 1
    condition: and(succeededOrFailed(), eq(variables.onnxruntimeBuildSucceeded, 'true')) # ensure all tests are run when the build successed
  
#  - script: |-
#      cd ./build/RelWithDebInfo
#      export PYTHONPATH=$PWD
#      python \
#        /stage/huggingface-transformers/examples/pytorch/translation/run_translation.py \
#        --dataset_name wmt16 \
#        --dataset_config ro-en \
#        --model_name_or_path facebook/bart-large \
#        --output_dir ./tst-translation \
#        --do_train \
#        --label_smoothing 0.1 \
#        --logging_steps 20 \
#        --overwrite_output_dir \
#        --per_device_train_batch_size 16 \
#        --predict_with_generate \
#        --source_lang en --target_lang ro \
#        --warmup_steps 5 \
#        --fp16 \
#        --max_steps 260 \
#        --dataloader_num_workers 1 \
#        --ort \
#        --skip_memory_metrics 
#      python ../../orttraining/tools/ci_test/compare_huggingface.py \
#        ci-pipeline-actual.json \
#        ../../orttraining/tools/ci_test/results/ci-mi100.huggingface.bart-large-rocm4.3.1.json
#    displayName: 'Run Python Hugging-Face BART-L test'
#    condition: succeededOrFailed() # ensure all tests are run
  
  # todo: investigate RoBERTa high run variability on ROCm 4.3.1
  #- script: |-
  #    cd ./build/RelWithDebInfo
  #    export PYTHONPATH=$PWD
  #    python \
  #      /stage/huggingface-transformers/examples/pytorch/question-answering/run_qa.py \
  #      --model_name_or_path roberta-large \
  #      --dataset_name squad \
  #      --do_train \
  #      --per_device_train_batch_size 16 \
  #      --learning_rate 3e-5 \
  #      --max_steps 260 \
  #      --max_seq_length 384 \
  #      --doc_stride 128 \
  #      --output_dir ./roberta_res \
  #      --overwrite_output_dir \
  #      --logging_steps 20 \
  #      --fp16 \
  #      --dataloader_num_workers 1 \
  #      --ort \
  #      --skip_memory_metrics
  #    python ../../orttraining/tools/ci_test/compare_huggingface.py \
  #      ci-pipeline-actual.json \
  #      ../../orttraining/tools/ci_test/results/ci-mi100.huggingface.roberta-large-rocm4.3.1.json
  #  displayName: 'Run Python Hugging-Face RoBERTa-L test'
  #  condition: succeededOrFailed() # ensure all tests are run
  
  - task: CmdLine@2
    inputs:
      script: |-
        cd ./build/RelWithDebInfo
        export PYTHONPATH=$PWD
        export ORTMODULE_ONNX_OPSET_VERSION=12
        python \
          /stage/huggingface-transformers/examples/pytorch/language-modeling/run_mlm.py \
          --model_name_or_path distilbert-base-uncased \
          --dataset_name wikitext \
          --dataset_config_name wikitext-2-raw-v1 \
          --do_train \
          --max_steps 260 \
          --logging_steps 20 \
          --output_dir ./test-mlm-bbu \
          --overwrite_output_dir \
          --per_device_train_batch_size 32 \
          --fp16 \
          --dataloader_num_workers 1 \
          --ort \
          --skip_memory_metrics
        python ../../orttraining/tools/ci_test/compare_huggingface.py \
          ci-pipeline-actual.json \
          ../../orttraining/tools/ci_test/results/ci-mi100.huggingface.distilbert-base-rocm4.3.1.json
    displayName: 'Run Python Hugging-Face DistilBERT test'
    retryCountOnTaskFailure: 1
    condition: and(succeededOrFailed(), eq(variables.onnxruntimeBuildSucceeded, 'true')) # ensure all tests are run when the build successed
  
  #- script: |-
  #    cd ./build/RelWithDebInfo
  #    export PYTHONPATH=$PWD
  #    python \
  #      /stage/huggingface-transformers/examples/pytorch/text-classification/run_glue.py \
  #      --model_name_or_path microsoft/deberta-v2-xxlarge \
  #      --task_name MRPC \
  #      --do_train \
  #      --max_seq_length 128 \
  #      --per_device_train_batch_size 4 \
  #      --learning_rate 3e-6 \
  #      --max_steps 260 \
  #      --output_dir ./deberta_res \
  #      --overwrite_output_dir \
  #      --logging_steps 20 \
  #      --fp16 \
  #      --dataloader_num_workers 1 \
  #      --ort \
  #      --skip_memory_metrics 
  #  displayName: 'Run Python Hugging-Face DeBERTa-XXL v2 test'
  #  condition: succeededOrFailed() # ensure all tests are run
  
  #- script: |-
  #    cd ./build/RelWithDebInfo
  #    export PYTHONPATH=$PWD
  #    python \
  #      /stage/huggingface-transformers/examples/pytorch/translation/run_translation.py \
  #      --source_prefix '"translate English to Romanian:"' \
  #      --dataset_name wmt16 \
  #      --dataset_config ro-en \
  #      --model_name_or_path t5-large \
  #      --output_dir ./tst-translation \
  #      --do_train \
  #      --label_smoothing 0.1 \
  #      --logging_steps 20 \
  #      --overwrite_output_dir \
  #      --per_device_train_batch_size 16 \
  #      --predict_with_generate \
  #      --source_lang en \
  #      --target_lang ro \
  #      --warmup_steps 5 \
  #      --fp16 \
  #      --max_steps 260 \
  #      --dataloader_num_workers 1 \
  #      --ort \
  #      --skip_memory_metrics
  #    python ../../orttraining/tools/ci_test/compare_huggingface.py \
  #      ci-pipeline-actual.json \
  #      ../../orttraining/tools/ci_test/results/ci-mi100.huggingface.t5-large.json 
  #  displayName: 'Run Python Hugging-Face T5-L test'
  #  condition: succeededOrFailed() # ensure all tests are run
  
  - task: CmdLine@2
    inputs:
      script: |-
        python orttraining/tools/ci_test/download_azure_blob_archive.py \
          --azure_blob_url https://onnxruntimetestdata.blob.core.windows.net/training/onnxruntime_training_data.zip?snapshot=2020-06-15T23:17:35.8314853Z \
          --target_dir training_e2e_test_data \
          --archive_sha256_digest B01C169B6550D1A0A6F1B4E2F34AE2A8714B52DBB70AC04DA85D371F691BDFF9
    condition: and(succeededOrFailed(), eq(variables.onnxruntimeBuildSucceeded, 'true')) # ensure all tests are run when the build successed
    displayName: 'Download onnxruntime_training_data.zip data'
  
  - task: CmdLine@2
    inputs:
      script: |-
        python orttraining/tools/ci_test/run_batch_size_test.py \
            --binary_dir build/RelWithDebInfo \
            --model_root training_e2e_test_data/models \
          --gpu_sku MI100_32G
    displayName: 'Run C++ BERT-L batch size test'
    retryCountOnTaskFailure: 1
    condition: and(succeededOrFailed(), eq(variables.onnxruntimeBuildSucceeded, 'true')) # ensure all tests are run when the build successed
  
  - task: CmdLine@2
    inputs:
      script: |-
        python orttraining/tools/ci_test/run_bert_perf_test.py \
          --binary_dir build/RelWithDebInfo \
          --model_root training_e2e_test_data/models \
          --training_data_root training_e2e_test_data/data \
          --gpu_sku MI100_32G
    displayName: 'Run C++ BERT-L performance test'
    retryCountOnTaskFailure: 1
    condition: and(succeededOrFailed(), eq(variables.onnxruntimeBuildSucceeded, 'true')) # ensure all tests are run when the build successed
  
  - task: CmdLine@2
    inputs:
      script: |-
        python orttraining/tools/ci_test/run_convergence_test.py \
          --binary_dir build/RelWithDebInfo \
          --model_root training_e2e_test_data/models \
          --training_data_root training_e2e_test_data/data \
          --gpu_sku MI100_32G
    displayName: 'Run C++ BERT-L convergence test'
    retryCountOnTaskFailure: 1
    condition: and(succeededOrFailed(), eq(variables.onnxruntimeBuildSucceeded, 'true')) # ensure all tests are run when the build successed
