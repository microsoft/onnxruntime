parameters:
- name: RunOnnxRuntimeTests
  displayName: Run Tests?
  type: boolean
  default: true

- name: DoCompliance
  displayName: Run Compliance Tasks?
  type: boolean
  default: true

- name: DoEsrp
  displayName: Run code sign tasks? Must be true if you are doing an Onnx Runtime release.
  type: boolean
  default: false

- name: IsReleaseBuild
  displayName: Is a release build? Set it to true if you are doing an Onnx Runtime release.
  type: boolean
  default: false

jobs:
- template: templates/c-api-cpu.yml
  parameters:
    RunOnnxRuntimeTests: ${{ parameters.RunOnnxRuntimeTests }}
    DoCompliance: ${{ parameters.DoCompliance }}
    DoEsrp: ${{ parameters.DoEsrp }}
    IsReleaseBuild: ${{ parameters.IsReleaseBuild }}
    OrtNugetPackageId: 'Microsoft.ML.OnnxRuntime'
    AdditionalBuildFlags: '--use_openmp'
    AdditionalWinBuildFlags: '--enable_onnx_tests --enable_wcos'

- job: Linux_C_API_Packaging_GPU_x64
  workspace:
    clean: all
  timeoutInMinutes:  120
  pool: 'Linux-GPU-CUDA10'
  variables:    
    CUDA_VERSION: '11.0'
  steps:
    - template: templates/set-version-number-variables-step.yml
    - template: templates/get-docker-image-steps.yml
      parameters:
        Dockerfile: tools/ci_build/github/linux/docker/Dockerfile.manylinux2014_cuda11
        Context: tools/ci_build/github/linux/docker
        DockerBuildArgs: "--build-arg BUILD_UID=$( id -u )"
        Repository: onnxruntimecuda11build
    - task: CmdLine@2
      inputs:
        script: |
          mkdir -p $HOME/.onnx
          docker run --gpus all -e CC=/opt/rh/devtoolset-8/root/usr/bin/cc -e CXX=/opt/rh/devtoolset-8/root/usr/bin/c++ -e CFLAGS="-g -O3" -e CXXFLAGS="-g -O3" -e NVIDIA_VISIBLE_DEVICES=all --rm --volume /data/onnx:/data/onnx:ro --volume $(Build.SourcesDirectory):/onnxruntime_src --volume $(Build.BinariesDirectory):/build \
          --volume /data/models:/build/models:ro --volume $HOME/.onnx:/home/onnxruntimedev/.onnx -e NIGHTLY_BUILD onnxruntimecuda11build \
          /opt/python/cp37-cp37m/bin/python3 /onnxruntime_src/tools/ci_build/build.py --build_dir /build --config Release \
          --skip_submodule_sync  --parallel --build_shared_lib --use_cuda --cuda_version=$(CUDA_VERSION) --cuda_home=/usr/local/cuda-$(CUDA_VERSION) --cudnn_home=/usr/local/cuda-$(CUDA_VERSION) --cmake_extra_defines CMAKE_CUDA_HOST_COMPILER=/opt/rh/devtoolset-8/root/usr/bin/cc
        workingDirectory: $(Build.SourcesDirectory)

    - template: templates/c-api-artifacts-package-and-publish-steps-posix.yml
      parameters:
          buildConfig: 'Release'
          artifactName: 'onnxruntime-linux-x64-gpu-$(OnnxRuntimeVersion)'
          artifactNameNoVersionString:  'onnxruntime-linux-x64-gpu'
          libraryName: 'libonnxruntime.so.$(OnnxRuntimeVersion)'
          commitId: $(OnnxRuntimeGitCommitHash)

    - template: templates/component-governance-component-detection-steps.yml
      parameters :
        condition : 'succeeded'
    - template: templates/clean-agent-build-directory-step.yml


- template: templates/win-ci.yml
  parameters:
    IsReleaseBuild: ${{ parameters.IsReleaseBuild }}
    ort_build_pool_name: 'Win-GPU-2019'
    DoCompliance: ${{ parameters.DoCompliance }}
    DoEsrp: ${{ parameters.DoEsrp }}
    OrtNugetPackageId: 'Microsoft.ML.OnnxRuntime.Gpu'
    job_name_suffix: gpu
    EnvSetupScript: setup_env_cuda_11.bat
    buildArch: x64
    msbuildPlatform: x64
    packageName: x64-gpu
    buildparameter: --use_cuda --cuda_version=11.0 --cuda_home="C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.0" --cudnn_home="C:\local\cudnn-11.0-windows-x64-v8.0.2.39\cuda" --enable_onnx_tests --enable_wcos
    runTests: true
    buildJava: false
