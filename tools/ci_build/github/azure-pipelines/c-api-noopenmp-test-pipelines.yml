resources:
  pipelines:
  - pipeline: build
    source: 'Zip-Nuget-Java-Nodejs Packaging Pipeline'
    trigger: true
    branch: main

stages:
- stage: Setup
  jobs:
  - job: Restore_And_Use_Variables
    displayName: 'Restore and Use Build Parameters'
    pool:
      name: 'onnxruntime-Ubuntu2204-AMD-CPU'
    steps:
    - download: build # This refers to the 'build' pipeline alias defined in resources.
      artifact: 'parameters_artifact' # This must match the ArtifactName from the source pipeline.
      displayName: 'Download Parameters Artifact'

    # Read the downloaded file and set the key-value pairs as pipeline variables.
    - bash: |
        echo "Loading parameters from downloaded artifact..."
        # The download task places the artifact in a directory named after the pipeline resource alias.
        FILE_PATH="$(Pipeline.Workspace)/build/parameters_artifact/parameters.txt"

        if [ -f "$FILE_PATH" ]; then
          echo "Found parameters file at: $FILE_PATH"
          echo "--- File Content ---"
          cat "$FILE_PATH"
          echo "--------------------"

          # Read each line, splitting it into a key and value at the '=' character.
          while IFS='=' read -r key value || [[ -n "$key" ]]; do
            if [ -n "$key" ]; then
              echo "Setting pipeline variable: '$key' to '$value'"
              # The 'task.setvariable' logging command creates a variable available to subsequent steps in the job.
              echo "##vso[task.setvariable variable=$key]$value"
            fi
          done < "$FILE_PATH"

          echo "Variables have been restored."
        else
          echo "ERROR: Parameters file not found at '$FILE_PATH'"
          exit 1
        fi
      displayName: 'Restore Parameters as Pipeline Variables'

    - script: |
        echo "Verifying the restored variables:"
        echo "IsReleaseBuild is: $(IsReleaseBuild)"
        echo "PreReleaseVersionSuffixString is: $(PreReleaseVersionSuffixString)"
        echo "PreReleaseVersionSuffixNumber is: $(PreReleaseVersionSuffixNumber)"
      displayName: 'Verify Restored Variables'

    # Almost the same as the step in set_packaging_variables_stage.yml except the following one use vars instead of parameters as input
    - bash: |
        # Do not output ##vso[] commands with `set -x` or they may be parsed again and include a trailing quote.
        set +x
        if [[ "$(IsReleaseBuild)" = True && "$(PreReleaseVersionSuffixString)" != "none"  ]]; then
          if [[ "$(PreReleaseVersionSuffixNumber)" -eq 0 ]]; then
            echo "##vso[task.setvariable variable=ReleaseVersionSuffix;isOutput=true]-$(PreReleaseVersionSuffixString)"
          else
            echo "##vso[task.setvariable variable=ReleaseVersionSuffix;isOutput=true]-$(PreReleaseVersionSuffixString).$(PreReleaseVersionSuffixNumber)"
          fi
        else
          echo "##vso[task.setvariable variable=ReleaseVersionSuffix;isOutput=true]"
        fi
      name: Set_Release_Version_Suffix

- stage: Android_Java_API_AAR_Testing_Full
  dependsOn: Setup
  jobs:
  - template: templates/android-java-api-aar-test.yml
    parameters:
      artifactName: 'onnxruntime-android-full-aar'
      ReleaseVersionSuffix: $(ReleaseVersionSuffix)

- stage: Final_AAR_Testing_Android_QNN
  dependsOn: Setup
  jobs:
  - template: templates/android-java-api-aar-test.yml
    parameters:
      artifactName: 'onnxruntime-android-qnn-aar'
      packageName: 'onnxruntime-android-qnn'
      #TODO: get this information from the setup stage
      QnnSDKVersion: '2.36.1.250708'

- template: nuget/templates/test_win.yml
  parameters:
    AgentPool: 'onnxruntime-Win-CPU-2022'
    NugetPackageName: 'Microsoft.ML.OnnxRuntime'
    ArtifactSuffix: 'CPU'

- template: nuget/templates/test_android.yml
  parameters:
    AgentPool : 'onnxruntime-Win-CPU-2022'
    ArtifactSuffix: 'CPU'

- template: nuget/templates/test_linux.yml
  parameters:
    AgentPool: onnxruntime-Ubuntu2204-AMD-CPU
    NugetPackageName: 'Microsoft.ML.OnnxRuntime'
    ArtifactSuffix: 'CPU'

- template: nuget/templates/test_macos.yml
  parameters:
    AgentPool: macOS-14
    ArtifactSuffix: 'CPU'

- template: nodejs/templates/test_win.yml
  parameters:
    AgentPool: 'onnxruntime-Win-CPU-2022'
    StageSuffix: 'Win_CPU_x64'

- template: nodejs/templates/test_linux.yml
  parameters:
    AgentPool: 'onnxruntime-Ubuntu2204-AMD-CPU'
    StageSuffix: 'Linux_CPU_x64'

- template: nodejs/templates/test_macos.yml
  parameters:
    StageSuffix: 'macOS_CPU_x64'

- template: templates/final-jar-testing.yml
  parameters:
    OS: Windows
    PoolName: 'onnxruntime-Win-CPU-2022'

- template: templates/final-jar-testing.yml
  parameters:
    OS: Linux
    PoolName: 'onnxruntime-Ubuntu2204-AMD-CPU'

- template: templates/final-jar-testing.yml
  parameters:
    OS: MacOS
    PoolName: 'macOS-14'


- stage: GPU_JAR_Testing
  dependsOn: Setup
  jobs:
  - job: Final_Jar_Testing_Windows_GPU
    workspace:
      clean: all
    pool: 'onnxruntime-Win2022-GPU-A10'
    timeoutInMinutes: 60
    variables:
    - name: runCodesignValidationInjection
      value: false

    steps:
    - template: templates/set-version-number-variables-step.yml

    - template: templates/jobs/download_win_gpu_library.yml
      parameters:
        CudaVersion: 12.2
        DownloadCUDA: true
        DownloadTRT: true

    - download: build
      artifact: 'onnxruntime-java-gpu'
      displayName: 'Download Final Jar'

    - download: build
      artifact: 'onnxruntime-java-tools'
      displayName: 'Download Jar Tools'

    - task: CmdLine@2
      inputs:
        script: |
          mkdir final-jar
          move $(Pipeline.Workspace)/build/onnxruntime-java-gpu/* final-jar
          move $(Pipeline.Workspace)/build/onnxruntime-java-tools/* final-jar
          cd final-jar
          mkdir test
          pushd test
          jar xf $(Build.BinariesDirectory)\final-jar\testing.jar
          popd
          java -DUSE_CUDA=1 -jar junit-platform-console-standalone-1.6.2.jar -cp .;.\test;protobuf-java-3.25.5.jar;onnxruntime_gpu-$(OnnxRuntimeVersion).jar --scan-class-path --fail-if-no-tests --disable-banner
        workingDirectory: '$(Build.BinariesDirectory)'

  - job: Final_Jar_Testing_Linux_GPU
    workspace:
      clean: all
    pool:
      name: 'Onnxruntime-Linux-GPU-A10'
      os: linux
    variables:
    - name: runCodesignValidationInjection
      value: false
    - name: docker_base_image
      value: onnxruntimebuildcache.azurecr.io/internal/azureml/onnxruntime/build/cuda12_x64_almalinux8_gcc12:20250724.1
    timeoutInMinutes: 60
    steps:
    - checkout: self
      submodules: false
    - template: templates/set-version-number-variables-step.yml

    - template: templates/flex-downloadPipelineArtifact.yml
      parameters:
        StepName: 'Download Final Jar'
        ArtifactName: onnxruntime-java-gpu
        TargetPath: '$(Build.BinariesDirectory)/final-jar'

    - template: templates/get-docker-image-steps.yml
      parameters:
        Dockerfile: tools/ci_build/github/linux/docker/Dockerfile.package_ubi8_cuda_tensorrt10_0
        Context: tools/ci_build/github/linux/docker/
        DockerBuildArgs: "
        --build-arg BUILD_UID=$( id -u )
        --build-arg BASEIMAGE=${{ variables.docker_base_image }}
        --build-arg TRT_VERSION=${{ variables.linux_trt_version }}
        "
        Repository: onnxruntimeubi8packagestest

    - bash: |
        docker run -e SYSTEM_COLLECTIONURI --rm \
          --gpus all \
          --volume $(Build.SourcesDirectory):/onnxruntime_src \
          --volume $(Build.BinariesDirectory):/build \
          --volume /data/models:/build/models:ro \
          onnxruntimeubi8packagestest \
          /bin/bash /onnxruntime_src/tools/ci_build/github/linux/java_linux_final_test.sh -r /build -v $(OnnxRuntimeVersion)
      displayName: 'Test'

- template: nuget/templates/test_win.yml
  parameters:
    AgentPool: 'onnxruntime-Win2022-GPU-A10'
    NugetPackageName: 'Microsoft.ML.OnnxRuntime.Gpu'
    ArtifactSuffix: 'GPU'
    StageSuffix: 'GPU'
    CudaVersion: 12.2

- template: nuget/templates/test_win.yml
  parameters:
    AgentPool: 'onnxruntime-Win2022-GPU-A10'
    NugetPackageName: 'Microsoft.ML.OnnxRuntime.Gpu.Windows'
    ArtifactSuffix: 'GPU'
    StageSuffix: 'GPU'
    MoreSuffix: '_Windows'
    CudaVersion: 12.2

- template: nuget/templates/test_linux.yml
  parameters:
    AgentPool: Onnxruntime-Linux-GPU-A10
    ArtifactSuffix: 'GPU'
    StageSuffix: 'GPU'
    NugetPackageName: 'Microsoft.ML.OnnxRuntime.Gpu'
    CudaVersion: 12.2

- template: nuget/templates/test_linux.yml
  parameters:
    AgentPool: Onnxruntime-Linux-GPU-A10
    ArtifactSuffix: 'GPU'
    StageSuffix: 'GPU'
    MoreSuffix: '_Linux'
    NugetPackageName: 'Microsoft.ML.OnnxRuntime.Gpu.Linux'
    CudaVersion: 12.2



# Run GPU tests.
- stage: Windows_Packaging_cuda_Testing
  dependsOn: Setup
  jobs:
    - job: Windows_Packaging_cuda_Testing
      workspace:
        clean: all
      pool: onnxruntime-Win2022-GPU-A10
      timeoutInMinutes: 180
      steps:
        - checkout: self
          clean: true
          submodules: none

        - download: build
          artifact: 'Windows_Packaging_cuda_build_artifacts'
          displayName: 'Download Windows GPU Packages Build'

        - task: CmdLine@2
          inputs:
            script: |
              move $(Pipeline.Workspace)/build/Windows_Packaging_cuda_build_artifacts $(Build.BinariesDirectory)/RelWithDebInfo

        - template: templates/set-version-number-variables-step.yml

        - task: JavaToolInstaller@0
          inputs:
            versionSpec: "17"
            jdkArchitectureOption: x64
            jdkSourceOption: 'PreInstalled'

        - task: UsePythonVersion@0
          inputs:
            versionSpec: '3.12'
            addToPath: true
            architecture: x64

        - task: PipAuthenticate@1
          displayName: 'Pip Authenticate'
          inputs:
            artifactFeeds: 'Lotus'

        - task: PythonScript@0
          displayName: 'Update CTest Path References'
          inputs:
            scriptPath: '$(Build.SourcesDirectory)\tools\python\update_ctest_path.py'
            arguments: >
              "$(Build.BinariesDirectory)/RelWithDebInfo/CTestTestfile.cmake"
              "$(Build.BinariesDirectory)/RelWithDebInfo"

        - task: NodeTool@0
          inputs:
            versionSpec: '22.x'

        - template: templates/jobs/download_win_gpu_library.yml
          parameters:
            CudaVersion: 12.2
            DownloadCUDA: true
            DownloadTRT: true

        - task: PythonScript@0
          displayName: 'test'
          inputs:
            scriptPath: '$(Build.SourcesDirectory)\tools\ci_build\build.py'
            arguments: '--config RelWithDebInfo --use_binskim_compliant_compile_flags --enable_lto --disable_rtti --build_dir $(Build.BinariesDirectory) --skip_submodule_sync --build_shared_lib --test --enable_onnx_tests  $(TelemetryOption) '
            workingDirectory: '$(Build.BinariesDirectory)'
        # Previous stage only assembles the java binaries, testing will be done in this stage with GPU machine
        - template: templates/make_java_win_binaries.yml
          parameters:
            msbuildPlatform: x64
            java_artifact_id: onnxruntime_gpu
            buildOnly: false

- stage: Windows_Packaging_Tensorrt_Testing
  dependsOn: Setup
  jobs:
    - job: Windows_Packaging_tensorrt_Testing
      workspace:
        clean: all
      pool: onnxruntime-Win2022-GPU-A10
      timeoutInMinutes: 180
      steps:
        - checkout: self
          clean: true
          submodules: none


        - download: build
          artifact: 'Windows_Packaging_tensorrt_build_artifacts'
          displayName: 'Download Windows GPU Packages Build'

        - task: CmdLine@2
          inputs:
            script: |
              move $(Pipeline.Workspace)/build/Windows_Packaging_tensorrt_build_artifacts $(Build.BinariesDirectory)/RelWithDebInfo

        - template: templates/set-version-number-variables-step.yml

        - task: JavaToolInstaller@0
          inputs:
            versionSpec: "17"
            jdkArchitectureOption: x64
            jdkSourceOption: 'PreInstalled'

        - task: UsePythonVersion@0
          inputs:
            versionSpec: '3.12'
            addToPath: true
            architecture: x64

        - task: PipAuthenticate@1
          displayName: 'Pip Authenticate'
          inputs:
            artifactFeeds: 'Lotus'

        - task: PythonScript@0
          displayName: 'Update CTest Path References'
          inputs:
            scriptPath: '$(Build.SourcesDirectory)\tools\python\update_ctest_path.py'
            arguments: >
              "$(Build.BinariesDirectory)/RelWithDebInfo/CTestTestfile.cmake"
              "$(Build.BinariesDirectory)/RelWithDebInfo"

        - task: NodeTool@0
          inputs:
            versionSpec: '22.x'

        - template: templates/jobs/download_win_gpu_library.yml
          parameters:
            CudaVersion: 12.2
            DownloadCUDA: true
            DownloadTRT: true

        - task: PythonScript@0
          displayName: 'test'
          inputs:
            scriptPath: '$(Build.SourcesDirectory)\tools\ci_build\build.py'
            arguments: '--config RelWithDebInfo --use_binskim_compliant_compile_flags --enable_lto --disable_rtti --build_dir $(Build.BinariesDirectory) --skip_submodule_sync --build_shared_lib --test --enable_onnx_tests  $(TelemetryOption) '
            workingDirectory: '$(Build.BinariesDirectory)'
        # Previous stage only assembles the java binaries, testing will be done in this stage with GPU machine
        - template: templates/make_java_win_binaries.yml
          parameters:
            msbuildPlatform: x64
            java_artifact_id: onnxruntime_gpu
            buildOnly: false
