parameters:
- name: artifactName  
  type: string
  default: 'onnxruntime-linux-x64-gpu-tensorrt-$(OnnxRuntimeVersion)'

- name: artifactNameNoVersionString
  type: string
  default: 'onnxruntime-linux-x64-gpu-tensorrt'

- name: buildJava
  type: boolean
  default: false

- name: buildJavaOption
  type: string
  default: ''

- name: buildNodejs
  type: boolean
  default: true

- name: buildNodejsOption
  type: string
  default: ''

- name: CudaVersion
  displayName: CUDA version
  type: string
  default: '11.8'
  values:
    - 11.8
    - 12.2



# We only have CUDA/TRT on x64. We do not have a build for CUDA/TRT for ARM64.
# Therefore this file does not have an `OnnxruntimeNodejsBindingArch` parameter
  
stages:
- stage: Linux_C_API_Packaging_GPU_TensorRT_x64
  dependsOn: []
  variables:
    - name: linux_trt_version
      ${{ if eq(parameters.CudaVersion, '11.8') }}:
        value: 8.6.1.6-1.cuda11.8
      ${{ if eq(parameters.CudaVersion, '12.2') }}:
        value: 8.6.1.6-1.cuda12.0
    - name: docker_base_image
      ${{ if eq(parameters.CudaVersion, '11.8') }}:
        value: nvidia/cuda:11.8.0-cudnn8-devel-ubi8
      ${{ if eq(parameters.CudaVersion, '12.2') }}:
        value: nvidia/cuda:12.2.2-cudnn8-devel-ubi8
  jobs:
  - job:
    dependsOn: []
    workspace:
      clean: all
    timeoutInMinutes:  180
    pool: 'Onnxruntime-Linux-GPU'
    variables:
      - name: CUDA_VERSION_MAJOR
        ${{ if eq(parameters.CudaVersion, '11.8') }}:
          value: '11'
        ${{ if eq(parameters.CudaVersion, '12.2') }}:
          value: '12'
      - name: CUDA_VERSION
        value: ${{ parameters.CudaVersion }}
    steps:
      - checkout: self
        clean: true
        submodules: recursive
      - template: get-docker-image-steps.yml
        parameters:
          Dockerfile: tools/ci_build/github/linux/docker/Dockerfile.manylinux2_28_cuda
          Context: tools/ci_build/github/linux/docker
          DockerBuildArgs: "
          --network=host
          --build-arg BASEIMAGE=${{ variables.docker_base_image }}
          --build-arg TRT_VERSION=${{ variables.linux_trt_version }}
          --build-arg BUILD_UID=$( id -u )
          "
          Repository: onnxruntimecuda${{ variables.CUDA_VERSION_MAJOR }}xtrt86build
      - template: set-version-number-variables-step.yml

      - script: $(Build.SourcesDirectory)/tools/ci_build/github/linux/build_tensorrt_c_api_package.sh
        workingDirectory: $(Build.SourcesDirectory)
        displayName: 'Build and Test'

      - ${{ if eq(parameters.buildJava, true) }}:
          - template: java-api-artifacts-package-and-publish-steps-posix.yml
            parameters:
                arch: 'linux-x64'
                buildConfig: 'Release'
                artifactName: 'onnxruntime-java-linux-x64-tensorrt'
                version: '$(OnnxRuntimeVersion)'
                libraryName: 'libonnxruntime.so'
                nativeLibraryName: 'libonnxruntime4j_jni.so'

      - ${{ if eq(parameters.buildNodejs, 'true') }}:
          - template: nodejs-artifacts-package-and-publish-steps-posix.yml
            parameters:
              arch: 'x64'
              os: 'linux'
              artifactName: 'drop-onnxruntime-nodejs-linux-x64-tensorrt'

      - template: c-api-artifacts-package-and-publish-steps-posix.yml
        parameters:
            buildConfig: 'Release'
            artifactName: ${{ parameters.artifactName }}
            artifactNameNoVersionString: ${{ parameters.artifactNameNoVersionString }}
            libraryName: 'libonnxruntime.so.$(OnnxRuntimeVersion)'


      - template: component-governance-component-detection-steps.yml
        parameters :
          condition : 'succeeded'
      - template: clean-agent-build-directory-step.yml
