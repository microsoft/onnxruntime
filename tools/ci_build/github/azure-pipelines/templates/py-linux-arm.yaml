parameters:
- name: build_py_parameters  
  type: string
  default: ''

jobs:
- job: Linux_py_Wheels
  timeoutInMinutes: 240
  workspace:
    clean: all
  pool: 'aiinfra-linux-ARM64-CPU-2019'
  steps:
    - checkout: self
      clean: true
      submodules: recursive
    
    - template: set-nightly-build-option-variable-step.yml

    - template: get-docker-image-steps.yml
      parameters:
        Dockerfile: tools/ci_build/github/linux/docker/inference/x64/python/cpu/Dockerfile.manylinux2014_cpu
        Context: tools/ci_build/github/linux/docker/inference/x64/python/cpu
        DockerBuildArgs: "--build-arg BUILD_UID=$( id -u ) --build-arg BASEIMAGE=arm64v8/centos:7 --build-arg PLATFORM=aarch64"
        Repository: onnxruntimecpubuilpythonarm64

    - task: CmdLine@2
      displayName: 'Build Python Wheel'
      inputs:
        script: |
            mkdir -p $HOME/.onnx
            docker run --rm \
              --volume /data/onnx:/data/onnx:ro \
              --volume $(Build.SourcesDirectory):/onnxruntime_src \
              --volume $(Build.BinariesDirectory):/build \
              --volume /data/models:/build/models:ro \
              --volume $HOME/.onnx:/home/onnxruntimedev/.onnx \
              -w /onnxruntime_src \
              -e NIGHTLY_BUILD \
              -e BUILD_BUILDNUMBER \
              onnxruntimecpubuilpythonarm64 /bin/bash tools/ci_build/github/linux/build_linux_arm64_python_package.sh
                
    - task: PublishBuildArtifacts@1
      displayName: 'Publish Artifact: ONNXRuntime python wheel'
      inputs:
        PathtoPublish: '$(Build.BinariesDirectory)/dist'
        ArtifactName: onnxruntime

    - template: component-governance-component-detection-steps.yml
      parameters:
        condition: 'succeeded'

    - template: clean-agent-build-directory-step.yml