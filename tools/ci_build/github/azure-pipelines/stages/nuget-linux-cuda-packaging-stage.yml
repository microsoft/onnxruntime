parameters:
- name: CudaVersion
  type: string
  default: '11.8'
- name: docker_base_image
  type: string
- name: buildJava
  type: boolean
- name: buildNodejs
  type: boolean

stages:
- stage: Linux_C_API_Packaging_GPU
  dependsOn: []
  jobs:
  - job: Linux_C_API_Packaging_CUDA
    workspace:
      clean: all
    timeoutInMinutes: 150
    pool: 'onnxruntime-Ubuntu2204-AMD-CPU'
    variables:
    - name: CUDA_VERSION_MAJOR
      ${{ if eq(parameters.CudaVersion, '11.8') }}:
        value: '11'
      ${{ if eq(parameters.CudaVersion, '12.2') }}:
        value: '12'
    - name: CUDA_VERSION
      value: ${{ parameters.CudaVersion }}
    steps:
    - template: ../templates/set-version-number-variables-step.yml
    - template: ../templates/get-docker-image-steps.yml
      parameters:
        Dockerfile: tools/ci_build/github/linux/docker/inference/x86_64/default/cuda${{ variables.CUDA_VERSION_MAJOR }}/Dockerfile
        Context: tools/ci_build/github/linux/docker/inference/x86_64/default/cuda${{ variables.CUDA_VERSION_MAJOR }}
        DockerBuildArgs: "
        --build-arg BUILD_UID=$( id -u )
        "
        Repository: onnxruntimecuda${{ variables.CUDA_VERSION_MAJOR }}build

    - script: $(Build.SourcesDirectory)/tools/ci_build/github/linux/build_cuda_c_api_package.sh
      workingDirectory: $(Build.SourcesDirectory)
      displayName: 'Build CUDA C API Package'

    - ${{ if eq(parameters.buildJava, true) }}:
      - template: ../templates/java-api-artifacts-package-and-publish-steps-posix.yml
        parameters:
          arch: 'linux-x64'
          buildConfig: 'Release'
          artifactName: 'onnxruntime-java-linux-x64-cuda'
          version: '$(OnnxRuntimeVersion)'
          libraryName: 'libonnxruntime.so'
          nativeLibraryName: 'libonnxruntime4j_jni.so'

    - template: ../templates/c-api-artifacts-package-and-publish-steps-posix.yml
      parameters:
        buildConfig: 'Release'
        artifactName: 'onnxruntime-linux-x64-cuda-$(OnnxRuntimeVersion)'
        artifactNameNoVersionString: 'onnxruntime-linux-x64-cuda'
        libraryName: 'libonnxruntime.so.$(OnnxRuntimeVersion)'

    - template: ../templates/component-governance-component-detection-steps.yml
      parameters:
        condition: 'succeeded'
    - template: ../templates/clean-agent-build-directory-step.yml
  # Linux CUDA with TensorRT Packaging
  - job: Linux_C_API_Packaging_TensorRT
    dependsOn: []
    workspace:
      clean: all
    timeoutInMinutes: 180
    pool: 'onnxruntime-Ubuntu2204-AMD-CPU'
    variables:
    - name: CUDA_VERSION_MAJOR
      ${{ if eq(parameters.CudaVersion, '11.8') }}:
        value: '11'
      ${{ if eq(parameters.CudaVersion, '12.2') }}:
        value: '12'
    - name: CUDA_VERSION
      value: ${{ parameters.CudaVersion }}

    - name: linux_trt_version
      ${{ if eq(parameters.CudaVersion, '11.8') }}:
        value: 10.0.1.6-1.cuda11.8
      ${{ if eq(parameters.CudaVersion, '12.2') }}:
        value: 10.0.1.6-1.cuda12.4
    steps:
    - checkout: self
      clean: true
      submodules: recursive
    - template: ../templates/get-docker-image-steps.yml
      parameters:
        Dockerfile: tools/ci_build/github/linux/docker/inference/x86_64/default/cuda${{ variables.CUDA_VERSION_MAJOR }}/Dockerfile
        Context: tools/ci_build/github/linux/docker/inference/x86_64/default/cuda${{ variables.CUDA_VERSION_MAJOR }}
        DockerBuildArgs: "
          --build-arg TRT_VERSION=${{ variables.linux_trt_version }}
          --build-arg BUILD_UID=$( id -u )
          "
        Repository: onnxruntimecuda${{ variables.CUDA_VERSION_MAJOR }}xtrt86build
    - template: ../templates/set-version-number-variables-step.yml

    - script: $(Build.SourcesDirectory)/tools/ci_build/github/linux/build_tensorrt_c_api_package.sh
      workingDirectory: $(Build.SourcesDirectory)
      displayName: 'Build TensorRT C API Package'

    - ${{ if eq(parameters.buildJava, true) }}:
      - template: ../templates/java-api-artifacts-package-and-publish-steps-posix.yml
        parameters:
          arch: 'linux-x64'
          buildConfig: 'Release'
          artifactName: 'onnxruntime-java-linux-x64-tensorrt'
          version: '$(OnnxRuntimeVersion)'
          libraryName: 'libonnxruntime.so'
          nativeLibraryName: 'libonnxruntime4j_jni.so'

    - ${{ if eq(parameters.buildNodejs, 'true') }}:
      - template: ../templates/nodejs-artifacts-package-and-publish-steps-posix.yml
        parameters:
          arch: 'x64'
          os: 'linux'
          artifactName: 'drop-onnxruntime-nodejs-linux-x64-tensorrt'

    - template: ../templates/c-api-artifacts-package-and-publish-steps-posix.yml
      parameters:
        buildConfig: 'Release'
        artifactName: 'onnxruntime-linux-x64-tensorrt-$(OnnxRuntimeVersion)'
        artifactNameNoVersionString: 'onnxruntime-linux-x64-tensorrt'
        libraryName: 'libonnxruntime.so.$(OnnxRuntimeVersion)'


    - template: ../templates/component-governance-component-detection-steps.yml
      parameters:
        condition: 'succeeded'
    - template: ../templates/clean-agent-build-directory-step.yml
  # Linux CUDA Combined Testing and Publishing
- stage: Linux_Packaging_combined_CUDA
  dependsOn:
  - Linux_C_API_Packaging_GPU
  jobs:
  - job: Linux_Packaging_combined_CUDA
    condition: succeeded()
    workspace:
      clean: all
    pool: 'Onnxruntime-Linux-GPU'
    variables:
    - name: CUDA_VERSION_MAJOR
      ${{ if eq(parameters.CudaVersion, '11.8') }}:
        value: '11'
      ${{ if eq(parameters.CudaVersion, '12.2') }}:
        value: '12'
    - name: linux_trt_version
      ${{ if eq(parameters.CudaVersion, '11.8') }}:
        value: 10.0.1.6-1.cuda11.8
      ${{ if eq(parameters.CudaVersion, '12.2') }}:
        value: 10.0.1.6-1.cuda12.4
    steps:
    - checkout: self                           # due to checkout multiple repos, the root directory is $(Build.SourcesDirectory)/onnxruntime
      submodules: false
    - checkout: onnxruntime-inference-examples # due to checkout multiple repos, the root directory is $(Build.SourcesDirectory)/onnxruntime-inference-examples
      submodules: false

    - task: mspremier.PostBuildCleanup.PostBuildCleanup-task.PostBuildCleanup@3
      displayName: 'Clean Agent Directories'
      condition: always()

    - template: ../templates/get-docker-image-steps.yml
      parameters:
        ScriptName: $(Build.SourcesDirectory)/onnxruntime/tools/ci_build/get_docker_image.py
        Dockerfile: $(Build.SourcesDirectory)/onnxruntime/tools/ci_build/github/linux/docker/inference/x86_64/default/cuda${{ variables.CUDA_VERSION_MAJOR }}/Dockerfile
        Context: $(Build.SourcesDirectory)/onnxruntime/tools/ci_build/github/linux/docker/inference/x86_64/default/cuda${{ variables.CUDA_VERSION_MAJOR }}
        DockerBuildArgs: "--build-arg BASEIMAGE=${{ variables.docker_base_image }} --build-arg TRT_VERSION=${{ variables.linux_trt_version }} --build-arg BUILD_UID=$( id -u )"
        Repository: onnxruntimecuda${{ variables.CUDA_VERSION_MAJOR }}xtrt86build
        UpdateDepsTxt: false

    - template: ../templates/set-version-number-variables-step.yml
      parameters:
        versionFileDirectory: '$(Build.SourcesDirectory)/onnxruntime'
        workingDirectory: '$(Build.SourcesDirectory)/onnxruntime'
    - task: DownloadPipelineArtifact@2
      displayName: 'Download Pipeline Artifact - Combined GPU'
      inputs:
        artifactName: 'onnxruntime-linux-x64-cuda'
        targetPath: '$(Build.BinariesDirectory)/tgz-artifacts'

    - task: DownloadPipelineArtifact@2
      displayName: 'Download Pipeline Artifact - Combined GPU'
      inputs:
        artifactName: 'onnxruntime-linux-x64-tensorrt'
        targetPath: '$(Build.BinariesDirectory)/tgz-artifacts'

    - task: ShellScript@2
      displayName: 'Shell Script'
      inputs:
        scriptPath: 'onnxruntime/tools/ci_build/github/linux/extract_and_bundle_gpu_package.sh'
        args: '-a $(Build.BinariesDirectory)/tgz-artifacts'
        workingDirectory: '$(Build.BinariesDirectory)/tgz-artifacts'

    - task: ArchiveFiles@2
      inputs:
        rootFolderOrFile: '$(Build.BinariesDirectory)/tgz-artifacts/onnxruntime-linux-x64-gpu'
        includeRootFolder: false
        archiveType: 'tar' # Options: zip, 7z, tar, wim
        tarCompression: 'gz'
        archiveFile: '$(Build.ArtifactStagingDirectory)/onnxruntime-linux-x64-gpu-$(OnnxRuntimeVersion).tgz'
        replaceExistingArchive: true

    - template: ../templates/validate-package.yml
      parameters:
        PackageType: 'tarball'
        PackagePath: '$(Build.ArtifactStagingDirectory)'
        PackageName: 'onnxruntime-linux-x64-gpu-$(OnnxRuntimeVersion).tgz'
        ScriptPath: '$(Build.SourcesDirectory)/onnxruntime/tools/nuget/validate_package.py'
        PlatformsSupported: 'linux-x64'
        VerifyNugetSigning: false
        workingDirectory: '$(Build.ArtifactStagingDirectory)'


    - task: CmdLine@2
      displayName: 'Test C API application for GPU package'
      inputs:
        script: |
          docker run --gpus all -e CFLAGS="-Wp,-D_FORTIFY_SOURCE=2 -Wp,-D_GLIBCXX_ASSERTIONS -fstack-protector-strong -fstack-clash-protection -fcf-protection -O3 -Wl,--strip-all" -e CXXFLAGS="-Wp,-D_FORTIFY_SOURCE=2 -Wp,-D_GLIBCXX_ASSERTIONS -fstack-protector-strong -fstack-clash-protection -fcf-protection -O3 -Wl,--strip-all" -e NVIDIA_VISIBLE_DEVICES=all --rm --volume /data/models:/data/models --volume $(Build.SourcesDirectory):/src_dir \
          --volume $(Build.ArtifactStagingDirectory):/artifact_src -e NIGHTLY_BUILD onnxruntimecuda${{ variables.CUDA_VERSION_MAJOR }}xtrt86build \
          /src_dir/onnxruntime-inference-examples/c_cxx/squeezenet/run_capi_application.sh -o /src_dir/onnxruntime -p /artifact_src/onnxruntime-linux-x64-gpu-$(OnnxRuntimeVersion).tgz -w /src_dir/onnxruntime-inference-examples/c_cxx/squeezenet
        workingDirectory: '$(Build.ArtifactStagingDirectory)'

    - task: PublishPipelineArtifact@1
      inputs:
        targetPath: '$(Build.ArtifactStagingDirectory)/onnxruntime-linux-x64-gpu-$(OnnxRuntimeVersion).tgz'
        artifactName: 'onnxruntime-linux-x64-gpu'
    - template: ../templates/component-governance-component-detection-steps.yml
      parameters:
        condition: 'succeeded'
