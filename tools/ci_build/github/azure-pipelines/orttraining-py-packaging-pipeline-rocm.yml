trigger: none

stages:
- stage: Python_Packaging
  jobs:
    - job: ROCm_build_environment
      displayName: 'Construct ROCm wheels environment'
      timeoutInMinutes: 300
      workspace:
        clean: all
      pool: AMD-GPU
      steps:
      - template: templates/ get-docker-image-steps.yml
        parameters:
          Dockerfile: tools/ci_build/github/linux/docker/Dockerfile.manylinux2014_rocm4_3_1
          Context: tools/ci_build/github/linux/docker
          DockerBuildArgs: >-
            --build-arg TORCH_VERSION=1.11.0
            --build-arg INSTALL_DEPS_EXTRA_ARGS=-tmur
            --build-arg BUILD_UID=$(id -u)
            --network=host --build-arg POLICY=manylinux2014 --build-arg PLATFORM=x86_64
            --build-arg DEVTOOLSET_ROOTPATH=/opt/rh/devtoolset-10/root
            --build-arg PREPEND_PATH=/opt/rh/devtoolset-10/root/usr/bin:
            --build-arg LD_LIBRARY_PATH_ARG=/opt/rh/devtoolset-10/root/usr/lib64:/opt/rh/devtoolset-10/root/usr/lib:/opt/rh/devtoolset-10/root/usr/lib64/dyninst:/opt/rh/devtoolset-10/root/usr/lib/dyninst:/usr/local/lib64:/usr/local/lib
          Repository: onnxruntimetrainingrocmbuild-rocm4.3.1
      - template: templates/ get-docker-image-steps.yml
        parameters:
          Dockerfile: tools/ci_build/github/linux/docker/Dockerfile.manylinux2014_rocm5_1_1
          Context: tools/ci_build/github/linux/docker
          DockerBuildArgs: >-
            --build-arg TORCH_VERSION=1.11.0
            --build-arg INSTALL_DEPS_EXTRA_ARGS=-tmur
            --build-arg BUILD_UID=$(id -u)
            --network=host --build-arg POLICY=manylinux2014 --build-arg PLATFORM=x86_64
            --build-arg DEVTOOLSET_ROOTPATH=/opt/rh/devtoolset-10/root
            --build-arg PREPEND_PATH=/opt/rh/devtoolset-10/root/usr/bin:
            --build-arg LD_LIBRARY_PATH_ARG=/opt/rh/devtoolset-10/root/usr/lib64:/opt/rh/devtoolset-10/root/usr/lib:/opt/rh/devtoolset-10/root/usr/lib64/dyninst:/opt/rh/devtoolset-10/root/usr/lib/dyninst:/usr/local/lib64:/usr/local/lib
          Repository: onnxruntimetrainingrocmbuild-rocm5.1.1

    - job: ROCM_training_wheels
      timeoutInMinutes: 180
      displayName: 'Build ROCm wheels (inside container)'
      workspace:
        clean: all
      pool: AMD-GPU
      dependsOn:
      - ROCm_build_environment
      strategy:
        matrix:
          Python37 Torch1110 Rocm431:
            PythonVersion: '3.7'
            TorchVersion: '1.11.0'
            RocmVersion: '4.3.1'
          Python38 Torch1110 Rocm431:
            PythonVersion: '3.8'
            TorchVersion: '1.11.0'
            RocmVersion: '4.3.1'
          Python39 Torch1110 Rocm431:
            PythonVersion: '3.9'
            TorchVersion: '1.11.0'
            RocmVersion: '4.3.1'
          Python37 Torch1110 Rocm511:
            PythonVersion: '3.7'
            TorchVersion: '1.11.0'
            RocmVersion: '5.1.1'
          Python38 Torch1110 Rocm511:
            PythonVersion: '3.8'
            TorchVersion: '1.11.0'
            RocmVersion: '5.1.1'
          Python39 Torch1110 Rocm511:
            PythonVersion: '3.9'
            TorchVersion: '1.11.0'
            RocmVersion: '5.1.1'
      steps:

      - checkout: self
        clean: true
        submodules: recursive

      - template: templates/ set-python-manylinux-variables-step.yml

      - task: CmdLine@2
        inputs:
          script: |
            docker run --rm \
              --privileged \
              --ipc=host \
              --network=host \
              --cap-add=SYS_PTRACE \
              --security-opt seccomp=unconfined \
              -e CC=/opt/rh/devtoolset-10/root/usr/bin/cc -e CXX=/opt/rh/devtoolset-10/root/usr/bin/c++ -e CFLAGS="-Wp,-D_FORTIFY_SOURCE=2 -Wp,-D_GLIBCXX_ASSERTIONS -fstack-protector-strong -fstack-clash-protection -fcf-protection -O3 -Wl,--strip-all" -e CXXFLAGS="-Wp,-D_FORTIFY_SOURCE=2 -Wp,-D_GLIBCXX_ASSERTIONS -fstack-protector-strong -fstack-clash-protection -fcf-protection -O3 -Wl,--strip-all" \
              --volume $(Build.SourcesDirectory):/onnxruntime_src \
              --volume $(Build.BinariesDirectory):/build \
              --workdir /onnxruntime_src \
              --entrypoint $(PythonManylinuxDir)/bin/python3 \
              -e NIGHTLY_BUILD \
              -e BUILD_BUILDNUMBER \
              --user onnxruntimedev \
              onnxruntimetrainingrocmbuild-rocm$(RocmVersion) \
                /onnxruntime_src/tools/ci_build/build.py \
                  --config Release \
                  --use_rocm \
                    --rocm_version=$(RocmVersion) \
                    --rocm_home=/opt/rocm \
                    --nccl_home=/opt/rocm \
                  --update \
                  --parallel \
                  --build_dir /build \
                  --build \
                  --build_wheel \
                  --skip_tests \
                  --enable_training
          workingDirectory: $(Build.SourcesDirectory)
        displayName: 'Build onnxruntime (in container)'

      - script: |-
          python3 orttraining/tools/ci_test/download_azure_blob_archive.py \
            --azure_blob_url https://onnxruntimetestdata.blob.core.windows.net/training/onnxruntime_training_data.zip?snapshot=2020-06-15T23:17:35.8314853Z \
            --target_dir $(Build.SourcesDirectory)/training_e2e_test_data \
            --archive_sha256_digest B01C169B6550D1A0A6F1B4E2F34AE2A8714B52DBB70AC04DA85D371F691BDFF9
        displayName: 'Download onnxruntime_training_data.zip data'

      - script: |-
          echo "Tests will run using HIP_VISIBLES_DEVICES=$HIP_VISIBLE_DEVICES"
          video_gid=$(getent group | awk '/video/ {split($0,a,":"); print(a[3])}')
          echo "Found video_gid=$video_gid; attempting to set as pipeline variable"
          echo "##vso[task.setvariable variable=video]$video_gid"
          render_gid=$(getent group | awk '/render/ {split($0,a,":"); print(a[3])}')
          echo "Found render_gid=$render_gid; attempting to set as pipeline variable"
          echo "##vso[task.setvariable variable=render]$render_gid"
        displayName: 'Find video and render gid to be mapped into container'

      - script: |-
          echo "video=$video"
          echo "render=$render"
          docker run --rm \
            --device=/dev/kfd \
            --device=/dev/dri \
            --group-add $(video) \
            --group-add $(render) \
            --privileged \
            --ipc=host \
            --network=host \
            --cap-add=SYS_PTRACE \
            --security-opt seccomp=unconfined \
            --volume $(Build.SourcesDirectory):/onnxruntime_src \
            --volume $(Build.BinariesDirectory):/build \
            --workdir /build/Release \
            --entrypoint /bin/bash \
            -e HIP_VISIBLE_DEVICES \
            -e NIGHTLY_BUILD \
            -e BUILD_BUILDNUMBER \
            --user onnxruntimedev \
            onnxruntimetrainingrocmbuild-rocm$(RocmVersion) \
               /onnxruntime_src/tools/ci_build/github/pai/pai_test_launcher.sh
        displayName: 'Run onnxruntime unit tests (in container)'

      - script: |-
          docker run --rm \
            --device=/dev/kfd \
            --device=/dev/dri \
            --group-add $(video) \
            --group-add $(render) \
            --privileged \
            --ipc=host \
            --network=host \
            --cap-add=SYS_PTRACE \
            --security-opt seccomp=unconfined \
            --volume $(Build.SourcesDirectory):/onnxruntime_src \
            --volume $(Build.BinariesDirectory):/build \
            --workdir /onnxruntime_src \
            --entrypoint $(PythonManylinuxDir)/bin/python3 \
            -e HIP_VISIBLE_DEVICES \
            -e NIGHTLY_BUILD \
            -e BUILD_BUILDNUMBER \
            --user onnxruntimedev \
            onnxruntimetrainingrocmbuild-rocm$(RocmVersion) \
              orttraining/tools/ci_test/run_batch_size_test.py \
                --binary_dir /build/Release \
                --model_root training_e2e_test_data/models \
                --gpu_sku MI100_32G
        displayName: 'Run C++ BERT-L batch size test (in container)'
        condition: succeededOrFailed() # ensure all tests are run

      - script: |-
          docker run --rm \
            --device=/dev/kfd \
            --device=/dev/dri \
            --group-add $(video) \
            --group-add $(render) \
            --privileged \
            --ipc=host \
            --network=host \
            --cap-add=SYS_PTRACE \
            --security-opt seccomp=unconfined \
            --volume $(Build.SourcesDirectory):/onnxruntime_src \
            --volume $(Build.BinariesDirectory):/build \
            --workdir /onnxruntime_src \
            --entrypoint $(PythonManylinuxDir)/bin/python3 \
            -e HIP_VISIBLE_DEVICES \
            -e NIGHTLY_BUILD \
            -e BUILD_BUILDNUMBER \
            --user onnxruntimedev \
            onnxruntimetrainingrocmbuild-rocm$(RocmVersion) \
              orttraining/tools/ci_test/run_bert_perf_test.py \
                --binary_dir /build/Release \
                --model_root training_e2e_test_data/models \
                --training_data_root training_e2e_test_data/data \
                --gpu_sku MI100_32G
        displayName: 'Run C++ BERT-L performance test (in container)'
        condition: succeededOrFailed() # ensure all tests are run

      - script: |-
          docker run --rm \
            --device=/dev/kfd \
            --device=/dev/dri \
            --group-add $(video) \
            --group-add $(render) \
            --privileged \
            --ipc=host \
            --network=host \
            --cap-add=SYS_PTRACE \
            --security-opt seccomp=unconfined \
            --volume $(Build.SourcesDirectory):/onnxruntime_src \
            --volume $(Build.BinariesDirectory):/build \
            --workdir /onnxruntime_src \
            --entrypoint $(PythonManylinuxDir)/bin/python3 \
            -e HIP_VISIBLE_DEVICES \
            -e NIGHTLY_BUILD \
            -e BUILD_BUILDNUMBER \
            --user onnxruntimedev \
            onnxruntimetrainingrocmbuild-rocm$(RocmVersion) \
              orttraining/tools/ci_test/run_convergence_test.py \
                --binary_dir /build/Release \
                --model_root training_e2e_test_data/models \
                --training_data_root training_e2e_test_data/data \
                --gpu_sku MI100_32G
        displayName: 'Run C++ BERT-L convergence test (in container)'
        condition: succeededOrFailed() # ensure all tests are run

      - task: CopyFiles@2
        displayName: 'Copy Python Wheel to: $(Build.ArtifactStagingDirectory)'
        inputs:
          SourceFolder: '$(Build.BinariesDirectory)'
          Contents: 'Release/dist/*.whl'
          TargetFolder: '$(Build.ArtifactStagingDirectory)'

      - task: CmdLine@2
        displayName: 'Build Python Documentation'
        condition: and(succeeded(), ne(variables['PythonVersion'], '3.9'))  # tensorflow not available on python 3.9
        inputs:
          script: |
            mkdir -p $HOME/.onnx
            docker run --rm \
              --device=/dev/kfd \
              --device=/dev/dri \
              --group-add $(video) \
              --group-add $(render) \
              --privileged \
              --ipc=host \
              --network=host \
              --cap-add=SYS_PTRACE \
              --security-opt seccomp=unconfined \
              --volume $(Build.SourcesDirectory):/onnxruntime_src \
              --volume $(Build.BinariesDirectory):/build \
              --entrypoint /bin/bash \
              -e HIP_VISIBLE_DEVICES \
              -e NIGHTLY_BUILD \
              -e BUILD_BUILDNUMBER \
              -e PythonManylinuxDir=$(PythonManylinuxdir) \
              onnxruntimetrainingrocmbuild-rocm$(RocmVersion) \
                /onnxruntime_src/tools/ci_build/github/pai/wrap_rocm_python_doc_publisher.sh
          workingDirectory: $(Build.SourcesDirectory)

      - task: CopyFiles@2
        displayName: 'Copy Python Documentation to: $(Build.ArtifactStagingDirectory)'
        condition: and(succeeded(), ne(variables['PythonVersion'], '3.9'))  # tensorflow not available on python 3.9
        inputs:
          SourceFolder: '$(Build.BinariesDirectory)/docs/training/html'
          Contents: '**'
          TargetFolder: '$(Build.ArtifactStagingDirectory)/training_html_doc'

      - task: PublishBuildArtifacts@1
        displayName: 'Upload Rocm wheel as build artifact'
        inputs:
          ArtifactName: onnxruntime_rocm

      - script: |
          python3 -m pip install azure-storage-blob==2.1.0
          files=($(Build.ArtifactStagingDirectory)/Release/dist/*.whl) && \
          echo ${files[0]} && \
          python3 tools/ci_build/upload_python_package_to_azure_storage_with_python.py \
              --python_wheel_path ${files[0]} \
              --account_name onnxruntimepackages \
              --account_key $(orttrainingpackagestorageaccountkey) \
              --container_name '$web'
        condition: and(succeeded(), eq(variables['DRY_RUN'], '0'))
        displayName: 'Upload Rocm wheel to release repository'

      - template: templates/ component-governance-component-detection-steps.yml
        parameters:
          condition: 'succeeded'

      - template: templates/ clean-agent-build-directory-step.yml
