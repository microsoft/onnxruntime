stages:
- ${{ if or(startsWith(variables['System.CollectionUri'], 'https://dev.azure.com/aiinfra/'),startsWith(variables['System.CollectionUri'], 'https://aiinfra.visualstudio.com/')) }}:
  - template: templates/web-ci.yml
    parameters:
      NpmPackagingMode: 'dev'
      IsReleasePipeline: true
      PoolName: 'aiinfra-Win-CPU-2022-web-beta'
      BuildStaticLib: true
      ExtraBuildArgs: ''

# This stage is to test if the combined build works on
# o Windows ARM64
# o Windows ARM64EC
# o Windows x64
# o Windows x86
# Now we don't have coverage for ARM64EC yet. Will add it.
- template: templates/win-ci.yml
  parameters:
    DoCompliance: false
    DoEsrp: false
    stage_name_suffix: CPU_x86_default
    EnvSetupScript: setup_env_x86.bat
    buildArch: x86
    msbuildPlatform: Win32
    packageName: x86
    buildparameter: --use_extensions --enable_onnx_tests
    runTests: true
    buildJava: false
    buildNodejs: false
    ort_build_pool_name: 'onnxruntime-Win-CPU-2022'

- template: templates/win-ci.yml
  parameters:
    DoCompliance: false
    DoEsrp: false
    stage_name_suffix: CPU_arm64_default
    EnvSetupScript: setup_env.bat
    buildArch: x64
    msbuildPlatform: arm64
    packageName: arm64
    buildparameter: --build_nodejs --arm64 --use_extensions  --enable_onnx_tests --path_to_protoc_exe $(Build.BinariesDirectory)\RelWithDebInfo\installed\bin\protoc.exe
    runTests: false
    buildJava: false
    buildNodejs: true
    ort_build_pool_name: 'onnxruntime-Win-CPU-2022'

- template: templates/win-ci.yml
  parameters:
    DoCompliance: false
    DoEsrp: false
    stage_name_suffix: CPU_x64_default
    EnvSetupScript: setup_env.bat
    buildArch: x64
    msbuildPlatform: x64
    packageName: x64
    buildparameter: --build_java --build_nodejs --use_extensions  --enable_onnx_tests
    runTests: true
    buildJava: true
    buildNodejs: true
    ort_build_pool_name: 'onnxruntime-Win-CPU-2022'

- ${{ if or(startsWith(variables['System.CollectionUri'], 'https://dev.azure.com/aiinfra/'),startsWith(variables['System.CollectionUri'], 'https://aiinfra.visualstudio.com/')) }}:
  # The settings below is the same as Windows GPU CI pipeline's CUDA job except here we set OnnxruntimeTestGpuDeviceId to 1
  - stage: cuda_multi_gpu
    dependsOn: []
    jobs:
    - template: templates/jobs/win-ci-vs-2022-job.yml
      parameters:
        BuildConfig: 'RelWithDebInfo'
        EnvSetupScript: setup_env_cuda_11.bat
        buildArch: x64
        additionalBuildFlags: --enable_pybind --build_java --build_nodejs --use_cuda --cuda_home="$(Agent.TempDirectory)\v11.8" --enable_cuda_profiling --cmake_extra_defines CMAKE_CUDA_ARCHITECTURES=86
        msbuildPlatform: x64
        isX86: false
        job_name_suffix: x64_RelWithDebInfo
        RunOnnxRuntimeTests: true
        RunStaticCodeAnalysis: false
        ORT_EP_NAME: CUDA
        WITH_CACHE: true
        MachinePool: onnxruntime-Win2022-GPU-MultiA10
        OnnxruntimeTestGpuDeviceId: 1

- ${{ if or(startsWith(variables['System.CollectionUri'], 'https://dev.azure.com/aiinfra/'),startsWith(variables['System.CollectionUri'], 'https://aiinfra.visualstudio.com/')) }}:
  # The settings below is the same as Windows GPU CI pipeline's CUDA job except here we set OnnxruntimeTestGpuDeviceId to 1
  - stage: trt_multi_gpu
    dependsOn: []
    jobs:
    - template: templates/jobs/win-ci-vs-2022-job.yml
      parameters:
        BuildConfig: 'RelWithDebInfo'
        EnvSetupScript: setup_env_trt.bat
        buildArch: x64
        additionalBuildFlags: --enable_pybind --build_java --build_nodejs --use_cuda --cuda_home="$(Agent.TempDirectory)\v11.8" --enable_cuda_profiling --use_tensorrt --tensorrt_home="C:\local\TensorRT-8.6.1.6.Windows10.x86_64.cuda-11.8" --cmake_extra_defines CMAKE_CUDA_ARCHITECTURES=86
        msbuildPlatform: x64
        isX86: false
        job_name_suffix: x64_RelWithDebInfo
        RunOnnxRuntimeTests: true
        RunStaticCodeAnalysis: false
        ORT_EP_NAME: TRT
        WITH_CACHE: true
        MachinePool: onnxruntime-Win2022-GPU-MultiA10
        OnnxruntimeTestGpuDeviceId: 1

- stage: Mimalloc
  dependsOn: [ ]
  jobs:
  - template: templates/jobs/win-ci-vs-2022-job.yml
    parameters:
      BuildConfig: 'Debug'
      EnvSetupScript: setup_env.bat
      buildArch: x64
      additionalBuildFlags: --disable_memleak_checker --use_mimalloc
      msbuildPlatform: x64
      isX86: false
      job_name_suffix: x64_mimalloc
      RunOnnxRuntimeTests: true
      RunStaticCodeAnalysis: false
      isTraining: false
      ORT_EP_NAME: CPU
      GenerateDocumentation: false
      EnablePython: false
      MachinePool: 'onnxruntime-Win-CPU-2022'

- stage: MemoryProfiling
  dependsOn: [ ]
  jobs:
  - template: templates/jobs/win-ci-vs-2022-job.yml
    parameters:
      BuildConfig: 'Debug'
      EnvSetupScript: setup_env.bat
      buildArch: x64
      additionalBuildFlags: --cmake_extra_defines onnxruntime_ENABLE_MEMORY_PROFILE=ON
      msbuildPlatform: x64
      isX86: false
      job_name_suffix: x64_no_memory_profiling
      RunOnnxRuntimeTests: false
      RunStaticCodeAnalysis: false
      isTraining: false
      ORT_EP_NAME: CPU
      GenerateDocumentation: false
      EnablePython: false
      MachinePool: 'onnxruntime-Win-CPU-2022'

- stage: MinimalBuildWithNoExceptions
  dependsOn: [ ]
  jobs:
  - template: templates/jobs/win-ci-vs-2022-job.yml
    parameters:
      BuildConfig: 'Debug'
      EnvSetupScript: setup_env.bat
      buildArch: x64
      additionalBuildFlags: --build_shared_lib --minimal_build --disable_exceptions
      msbuildPlatform: x64
      isX86: false
      job_name_suffix: x64_minimal_no_exception
      RunOnnxRuntimeTests: true
      RunStaticCodeAnalysis: false
      isTraining: false
      ORT_EP_NAME: CPU
      GenerateDocumentation: false
      EnablePython: false
      MachinePool: 'onnxruntime-Win-CPU-2022'

- stage: DebugNodeInputsOutputs
  dependsOn: [ ]
  jobs:
  - template: templates/jobs/win-ci-vs-2022-job.yml
    parameters:
      BuildConfig: 'Debug'
      EnvSetupScript: setup_env.bat
      buildArch: x64
      additionalBuildFlags: --build_shared_lib --cmake_extra_defines onnxruntime_DEBUG_NODE_INPUTS_OUTPUTS=ON
      msbuildPlatform: x64
      isX86: false
      job_name_suffix: x64_debug_node_input_output
      RunOnnxRuntimeTests: true
      RunStaticCodeAnalysis: false
      isTraining: false
      ORT_EP_NAME: CPU
      GenerateDocumentation: false
      EnablePython: false
      MachinePool: 'onnxruntime-Win-CPU-2022'

#Generate test coverage report and publish the data to a Cloud database. Only runs daily.
- stage: CodeCoverage
  dependsOn: [ ]
  jobs:
  - job: CodeCoverage
    workspace:
      clean: all
    timeoutInMinutes: 150
    variables:
      skipComponentGovernanceDetection: true
    pool: 'onnxruntime-Ubuntu2004-AMD-CPU'
    steps:
    - template: templates/set-version-number-variables-step.yml

    - task: CmdLine@2
      inputs:
        script: |
          set -e
          ln -s /data/models .
          #Build onnxruntime and run the instrumented program(unitests)
          LLVM_PROFILE_FILE="%p.profraw" CFLAGS="-g -fprofile-instr-generate -fcoverage-mapping" CXXFLAGS="-g -fprofile-instr-generate -fcoverage-mapping" CC=clang CXX=clang++  python3 $(Build.SourcesDirectory)/tools/ci_build/build.py --build_dir=$(Build.BinariesDirectory) --config Debug --parallel --skip_submodule_sync --build_shared_lib --enable_onnx_tests --cmake_extra_defines RUN_MODELTEST_IN_DEBUG_MODE=ON

          cd Debug
          ./onnxruntime_mlas_test
          #Merge the multiple prof data into a single indexed profile data file
          llvm-profdata merge -sparse -o ort.profdata *.profraw
          #Create coverage report, output the result to 'report.json'
          llvm-cov export -summary-only -instr-profile=ort.profdata onnxruntime_test_all -object onnxruntime_mlas_test -object onnx_test_runner -object onnxruntime_shared_lib_test -object onnxruntime_global_thread_pools_test $(Build.SourcesDirectory)/include/onnxruntime $(Build.SourcesDirectory)/onnxruntime/core $(Build.SourcesDirectory)/onnxruntime/contrib_ops > $(Build.BinariesDirectory)/report.json

          llvm-cov show -instr-profile=ort.profdata onnxruntime_test_all -object onnxruntime_mlas_test -object onnx_test_runner -object onnxruntime_shared_lib_test -object onnxruntime_global_thread_pools_test $(Build.SourcesDirectory)/include/onnxruntime $(Build.SourcesDirectory)/onnxruntime/core $(Build.SourcesDirectory)/onnxruntime/contrib_ops --format=html -output-dir=$(Build.ArtifactStagingDirectory)
        workingDirectory: $(Build.BinariesDirectory)

    - ${{ if or(startsWith(variables['System.CollectionUri'], 'https://dev.azure.com/aiinfra/'),startsWith(variables['System.CollectionUri'], 'https://aiinfra.visualstudio.com/')) }}:
      - task: AzureCLI@2
        displayName: 'Azure CLI'
        inputs:
          azureSubscription: AIInfraBuildOnnxRuntimeOSS
          scriptType: bash
          scriptPath: $(Build.SourcesDirectory)/tools/ci_build/github/linux/upload_code_coverage_data.sh
          arguments: '"$(Build.BinariesDirectory)/report.json" "https://aiinfra.visualstudio.com/Lotus/_build/results?buildId=$(Build.BuildId)" x64 linux default'
          workingDirectory: '$(Build.BinariesDirectory)'

      - task: PublishPipelineArtifact@1
        displayName: 'Publish Pipeline Artifact'
        inputs:
          targetPath: '$(Build.ArtifactStagingDirectory)'
          artifact: html
  - ${{ if or(startsWith(variables['System.CollectionUri'], 'https://dev.azure.com/aiinfra/'),startsWith(variables['System.CollectionUri'], 'https://aiinfra.visualstudio.com/')) }}:
    - template: templates/upload-code-coverage-data.yml

- stage: AndroidCustomBuildScript
  dependsOn: [ ]
  jobs:
  - job: AndroidCustomBuildScript
    workspace:
      clean: all
    pool: 'onnxruntime-Ubuntu2004-AMD-CPU'
    variables:
      dockerImageTag: onnxruntime-android-custom-build
    steps:
    - checkout: self
      submodules: false

    - task: UsePythonVersion@0
      inputs:
        versionSpec: '3.8'
        addToPath: true
        architecture: x64

    - task: CmdLine@2
      displayName: 'Run build_custom_android_package.py'
      inputs:
        script: |
          "$(Build.SourcesDirectory)/tools/android_custom_build/build_custom_android_package.py" \
            --docker_image_tag=$(dockerImageTag) \
            "$(Build.BinariesDirectory)/custom_android_package"
        workingDirectory: '$(Build.BinariesDirectory)'

    - task: CmdLine@2
      displayName: 'Clean up docker image'
      inputs:
        script: docker image rm $(dockerImageTag)
        workingDirectory: '$(Build.BinariesDirectory)'
      condition: succeededOrFailed()
