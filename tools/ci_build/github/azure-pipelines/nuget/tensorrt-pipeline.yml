parameters:
- name: RunOnnxRuntimeTests
  displayName: Run Tests?
  type: boolean
  default: true

- name: DoCompliance
  displayName: Run Compliance Tasks?
  type: boolean
  default: true

- name: DoEsrp
  displayName: Run code sign tasks? Must be true if you are doing an Onnx Runtime release.
  type: boolean
  default: false

- name: IsReleaseBuild
  displayName: Is a release build? Set it to true if you are doing an Onnx Runtime release.
  type: boolean
  default: false

variables:
  PackageName: 'Microsoft.ML.OnnxRuntime'

jobs:

- job: Linux_C_API_Packaging_GPU_TensorRT_x64
  workspace:
    clean: all
  timeoutInMinutes:  120
  pool: 'Onnxruntime-Linux-GPU'
  variables:
    CUDA_VERSION: '11.1'
  steps:
    - template: ../templates/set-version-number-variables-step.yml
    - template: ../templates/get-docker-image-steps.yml
      parameters:
        Dockerfile: tools/ci_build/github/linux/docker/Dockerfile.manylinux2014_cuda11.1_tensorrt7.2
        Context: tools/ci_build/github/linux/docker
        DockerBuildArgs: "--build-arg BUILD_UID=$( id -u )"
        Repository: onnxruntimecuda111trt72build
    - task: CmdLine@2
      inputs:
        script: |
          mkdir -p $HOME/.onnx
          docker run --gpus all -e CC=/opt/rh/devtoolset-8/root/usr/bin/cc -e CXX=/opt/rh/devtoolset-8/root/usr/bin/c++ -e CFLAGS="-Wp,-D_FORTIFY_SOURCE=2 -Wp,-D_GLIBCXX_ASSERTIONS -fstack-protector-strong -fstack-clash-protection -fcf-protection -O3 -Wl,--strip-all" -e CXXFLAGS="-Wp,-D_FORTIFY_SOURCE=2 -Wp,-D_GLIBCXX_ASSERTIONS -fstack-protector-strong -fstack-clash-protection -fcf-protection -O3 -Wl,--strip-all" -e NVIDIA_VISIBLE_DEVICES=all --rm --volume /data/onnx:/data/onnx:ro --volume $(Build.SourcesDirectory):/onnxruntime_src --volume $(Build.BinariesDirectory):/build \
          --volume /data/models:/build/models:ro --volume $HOME/.onnx:/home/onnxruntimedev/.onnx -e NIGHTLY_BUILD onnxruntimecuda111trt72build \
          /opt/python/cp37-cp37m/bin/python3 /onnxruntime_src/tools/ci_build/build.py --build_dir /build --config Release \
          --skip_submodule_sync --parallel --build_shared_lib --use_tensorrt --cuda_version=$(CUDA_VERSION) --cuda_home=/usr/local/cuda-$(CUDA_VERSION) --cudnn_home=/usr --tensorrt_home=/usr --cmake_extra_defines CMAKE_CUDA_HOST_COMPILER=/opt/rh/devtoolset-8/root/usr/bin/cc
        workingDirectory: $(Build.SourcesDirectory)

    - template: ../templates/c-api-tensorrt-artifacts-package-and-publish-steps-posix.yml
      parameters:
          buildConfig: 'Release'
          artifactName: 'onnxruntime-linux-x64-gpu-tensorrt-$(OnnxRuntimeVersion)'
          artifactNameNoVersionString:  'onnxruntime-linux-x64-gpu-tensorrt'
          libraryName: 'libonnxruntime.so.$(OnnxRuntimeVersion)'
          commitId: $(OnnxRuntimeGitCommitHash)

    - template: ../templates/component-governance-component-detection-steps.yml
      parameters :
        condition : 'succeeded'
    - template: ../templates/clean-agent-build-directory-step.yml
