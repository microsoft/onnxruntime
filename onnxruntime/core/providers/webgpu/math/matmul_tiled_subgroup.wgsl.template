// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT License.

#param tile_n
#param use_subgroup

fn load_a(batch : u32, m : u32, k_idx : u32) -> a_value_t {
  if (batch < uniforms.Batch && m < uniforms.M && k_idx < uniforms.k_of_a) {
    let offset = batch * uniforms.M * uniforms.k_of_a + m * uniforms.k_of_a + k_idx;
    return a[offset];
  }
  return a_value_t();
}

fn load_b(batch : u32, k : u32, n_idx : u32) -> b_value_t {
  if (batch < uniforms.Batch && k < uniforms.K && n_idx < uniforms.n_div_4) {
    let offset = batch * uniforms.K * uniforms.n_div_4 + k * uniforms.n_div_4 + n_idx;
    return b[offset];
  }
  return b_value_t();
}

fn write_output(batch : u32, m : u32, n_idx : u32, value : output_value_t) {
  if (batch < uniforms.Batch && m < uniforms.M && n_idx < uniforms.n_div_4) {
    let offset = batch * uniforms.M * uniforms.n_div_4 + m * uniforms.n_div_4 + n_idx;
    output[offset] = value;
  }
}

const tile_m_size : u32 = 64;
const tile_n_size : u32 = tile_n;
const tile_k_vec_size : u32 = 4;

var<workgroup> a_cache : array<array<a_value_t, tile_m_size>, tile_k_vec_size>;
var<workgroup> b_cache : array<array<b_value_t, tile_n_size>, tile_k_vec_size>;

$MAIN {
  let batch = workgroup_idx / (uniforms.M_tiles * uniforms.N_tiles);
  let m_global_base = ((workgroup_idx / uniforms.N_tiles) % uniforms.M_tiles) * tile_m_size;
  let n_global_base = (workgroup_idx % uniforms.N_tiles) * tile_n_size;

  let local_m = local_idx;
  let local_n = 0u;

  var results : array<output_element_t, tile_n_size>;
  for (var k_idx = 0u; k_idx < uniforms.K_tiles; k_idx++) {
    for (var a = 0u; a < tile_m_size; a += 16u) {
      // Loads a 16x4 vec of matrix A into the workgroup cache.
      let local_a_m = a + local_idx / tile_k_vec_size;
      let local_a_k = local_idx % tile_k_vec_size;
      a_cache[local_a_k][local_a_m] = load_a(batch,
                                             m_global_base + local_a_m,
                                             k_idx * tile_k_vec_size + local_a_k);
    }

    for (var b = 0u; b < tile_n_size; b += 16u) {
      // Loads and transposes a 16x4 vec of matrix B into the workgroup cache.
      let b_k_offset = local_idx / 4;
      let b_n_offset = b / 4 + local_idx % 4;
      let b_data = load_b(batch,
                          k_idx * 4 * tile_k_vec_size + b_k_offset,
                          n_global_base / 4 + b_n_offset);

      b_cache[b_k_offset / 4][4 * b_n_offset][b_k_offset % 4] = b_data[0];
      b_cache[b_k_offset / 4][4 * b_n_offset + 1][b_k_offset % 4] = b_data[1];
      b_cache[b_k_offset / 4][4 * b_n_offset + 2][b_k_offset % 4] = b_data[2];
      b_cache[b_k_offset / 4][4 * b_n_offset + 3][b_k_offset % 4] = b_data[3];
    }

    workgroupBarrier();

    for (var local_k_idx = 0u; local_k_idx < tile_k_vec_size; local_k_idx++) {
      let a_data = a_cache[local_k_idx][local_m];

#if use_subgroup
      if (sg_size >= tile_n_size) {
        let b_data = b_cache[local_k_idx][local_n + sg_id];
        for (var n_idx = 0u; n_idx < tile_n_size; n_idx++) {
          results[n_idx] += dot(a_data, subgroupShuffle(b_data, n_idx));
        }
      } else {
        for (var n_idx = 0u; n_idx < tile_n_size; n_idx++) {
          results[n_idx] += dot(a_data, b_cache[local_k_idx][local_n + n_idx]);
        }
      }
#else
      for (var n_idx = 0u; n_idx < tile_n_size; n_idx++) {
        results[n_idx] += dot(a_data, b_cache[local_k_idx][local_n + n_idx]);
      }
#endif
    }
    workgroupBarrier();
  }

  let m_base = m_global_base + local_m;
  let n_base = n_global_base + local_n;
  for (var n_idx = 0u; n_idx < tile_n_size / 4; n_idx++) {
    var output_data = output_value_t(results[4 * n_idx],
                                     results[4 * n_idx + 1u],
                                     results[4 * n_idx + 2u],
                                     results[4 * n_idx + 3u]);
    write_output(batch, m_base, n_base / 4 + n_idx, output_data);
  }
}  // MAIN
