// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT License.

#param has_attention_bias
#param head_size_vec
#param tile_size
#param tile_size_k_vec
#param sub_tile_count

// Note that this shader adopts similar algorithm with dp4a generation shader.
//
// This algorithm works to compute dot product of keys with queries parallelly,
// by processing on the k (head_size) dimension at each step amongst
// tile_size_k_vec threads, and utilizing the remaining threads in the workgroup
// to process additional rows of |present_key| in parallel (such that the values
// in shared memory (tile_q) for |q| can be reused). For each load of q, the
// tile_size_k_vec threads also reload |present_key| tile_size/sub_tile_count
// times to compute partial dot products of other |present_key| rows in order to
// complete all tile_size |present_key| rows in this workgroup and also reusing
// the loaded in register values of |q|.

// 1. Each workgroup processes one row of |q| and tile_size rows of |present_key|
//
// 2. Computation Process:
//    - Reads [tile_size][tile_size_k_vec] block of |present_key| data at a time
//    - Each thread within workgroup computes dot products of 4 A*B elements
//      since each k represents 4 elements of |present_key|
//    - Stores intermediate results in shared memory (inner_qk_values)
//    - Iterates through columns (head_size_vec) accumulating results in
//      inner_qk_values
//    - Performs final reduction sum in inner_qk_values for output

var<workgroup> tile_q: array<q_value_t, tile_size_k_vec>;
var<workgroup> inner_qk_values: array<array<q_element_t, tile_size_k_vec>, tile_size>;
var<workgroup> tile_qk: array<q_element_t, tile_size>;
var<workgroup> tile_output: array<present_value_value_t, head_size_vec>;
var<workgroup> qkv_values: array<array<present_value_value_t, tile_size_k_vec>, sub_tile_count>;

#if has_attention_bias
  fn loadAttentionBias(idx: u32) -> q_element_t
  {
    return attention_bias[idx];
  }
#else
  fn loadAttentionBias(idx: u32) -> q_element_t
  {
    return q_element_t(0);
  }
#endif

$MAIN {
  let local_row = u32(local_idx / tile_size_k_vec);
  let local_col = local_idx % tile_size_k_vec;
  let total_seq_offset = (workgroup_idx % uniforms.num_total_seq_length_tile) * tile_size;
  let head_idx = u32(workgroup_idx / uniforms.num_total_seq_length_tile);
  let q_offset = head_idx * head_size_vec;
  var total_sequence_length = uniforms.total_sequence_length;
  let present_offset = u32(head_idx / uniforms.n_reps) * uniforms.present_sequence_length * head_size_vec;
  for (var k: u32 = 0u; k < head_size_vec; k += tile_size_k_vec) {
    if (local_idx < tile_size_k_vec && k + local_idx < head_size_vec) {
      tile_q[local_idx] = q[q_offset + k + local_idx];
    }
    workgroupBarrier();
    let q_data = tile_q[local_col] * q_element_t(uniforms.alpha);
    if (k + local_col < head_size_vec) {
      for (var row_offset = 0u; row_offset < tile_size; row_offset += sub_tile_count) {
        if (total_seq_offset + row_offset + local_row < total_sequence_length) {
          inner_qk_values[row_offset + local_row][local_col] += dot(present_key[present_offset + (total_seq_offset + row_offset + local_row) * head_size_vec + k + local_col], q_data);
        }
      }
    }
    workgroupBarrier();
  }

  var sum = q_element_t(0);
  if (local_idx < tile_size && total_seq_offset + local_idx < total_sequence_length && head_idx < uniforms.num_heads) {
    for (var i = 0u; i < tile_size_k_vec; i++) {
      sum += inner_qk_values[local_idx][i];
    }

    sum = sum + loadAttentionBias(head_idx * total_sequence_length + total_seq_offset + local_idx);
    tile_qk[local_idx] = sum;
  }
  workgroupBarrier();

  if (head_idx >= uniforms.num_heads) {
    return;
  }

   // Calculate the max and sum in current split.
  var l_max = f32(-3.402823e+38f);
  for (var i = 0u; i < tile_size && (total_seq_offset + i) < total_sequence_length; i++) {
    l_max = max(l_max, f32(tile_qk[i]));
  }
  var l_sum = f32(0);
  for (var i = 0u; i < tile_size && (total_seq_offset + i) < total_sequence_length; i++) {
    l_sum += exp(f32(tile_qk[i]) - l_max);
  }
  if (local_idx == 0u) {
    let meta_offset = head_idx * uniforms.num_present_sequence_length_tile + workgroup_idx % uniforms.num_total_seq_length_tile;
    metadata[meta_offset] = metadata_value_t(l_max, l_sum);
  }

  tile_qk[local_idx] = q_element_t(exp(f32(sum) - l_max) / l_sum);
  workgroupBarrier();

  for (var k: u32 = 0u; k < head_size_vec; k += tile_size_k_vec) {
    var value = present_value_value_t(0);
    qkv_values[local_row][local_col] = present_value_value_t(0);
    workgroupBarrier();

    if (k + local_col < head_size_vec) {
      for (var row_offset = 0u; row_offset < tile_size; row_offset += sub_tile_count) {
        if (total_seq_offset + row_offset + local_row < total_sequence_length) {
          value += present_value[present_offset + (total_seq_offset + row_offset + local_row) * head_size_vec + k + local_col] * tile_qk[row_offset + local_row];
        }
      }
    }

    qkv_values[local_row][local_col] = value;
    workgroupBarrier();

    if (local_idx < tile_size_k_vec) {
      for (var i = 0u; i < sub_tile_count; i++) {
        tile_output[k + local_idx] += qkv_values[i][local_idx];
      }
    }
    workgroupBarrier();
  }

  if (head_idx >= uniforms.num_heads) {
    return;
  }

  for (var i = local_idx; i < head_size_vec; i += workgroup_size_x) {
    let out_offset = head_idx * uniforms.num_present_sequence_length_tile * head_size_vec + (workgroup_idx % uniforms.num_total_seq_length_tile) * head_size_vec + i;
    out_split_vx[out_offset] = tile_output[i];
  }
}
